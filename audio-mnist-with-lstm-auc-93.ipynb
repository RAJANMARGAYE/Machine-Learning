{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport librosa,librosa.display\nfrom tqdm.notebook import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' ","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:14:05.904852Z","iopub.execute_input":"2021-09-16T14:14:05.905189Z","iopub.status.idle":"2021-09-16T14:14:07.838794Z","shell.execute_reply.started":"2021-09-16T14:14:05.905100Z","shell.execute_reply":"2021-09-16T14:14:07.838021Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"path='../input/free-spoken-digits/free-spoken-digit-dataset-master/recordings/0_george_0.wav'\nraw_data,framerate=librosa.load(path)\nraw_data,framerate","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:14:07.840311Z","iopub.execute_input":"2021-09-16T14:14:07.840542Z","iopub.status.idle":"2021-09-16T14:14:08.564618Z","shell.execute_reply.started":"2021-09-16T14:14:07.840502Z","shell.execute_reply":"2021-09-16T14:14:08.563779Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"(array([-0.04374877, -0.04589297, -0.03884229, ..., -0.00196383,\n         0.00266265,  0.        ], dtype=float32),\n 22050)"},"metadata":{}}]},{"cell_type":"markdown","source":"### We will be reading sound file with the help of librosa library which will convert sound file into time series y, represented as a one-dimensional NumPy floating point array.","metadata":{}},{"cell_type":"code","source":"data=pd.DataFrame(columns=['raw_data','duration','digit'])\ndir_path='../input/free-spoken-digits/free-spoken-digit-dataset-master/recordings/'\nfor i in tqdm(os.listdir(dir_path)):\n        raw_data,frame_rate=librosa.load(dir_path+i)\n        duration=librosa.get_duration(raw_data,frame_rate)\n        data.loc[len(data.index)]=[raw_data,duration,i.split('_')[0]] # We are appending label as it in file name","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:14:08.566164Z","iopub.execute_input":"2021-09-16T14:14:08.566432Z","iopub.status.idle":"2021-09-16T14:15:12.066563Z","shell.execute_reply.started":"2021-09-16T14:14:08.566398Z","shell.execute_reply":"2021-09-16T14:15:12.065940Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c6aad5324944f73823dc80b32dc2550"}},"metadata":{}}]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:15:12.068578Z","iopub.execute_input":"2021-09-16T14:15:12.068841Z","iopub.status.idle":"2021-09-16T14:15:12.093774Z","shell.execute_reply.started":"2021-09-16T14:15:12.068809Z","shell.execute_reply":"2021-09-16T14:15:12.092934Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                            raw_data  duration digit\n0  [-0.00035317737, -0.0003979482, -0.00042274845...  0.442540     0\n1  [0.000108883556, 0.00013303479, 0.00024854412,...  0.386757     2\n2  [0.0017647212, 0.0026649828, 0.0028954616, 0.0...  0.452789     4\n3  [5.169994e-05, 6.9254784e-05, 6.970848e-05, 6....  0.366893     1\n4  [0.0019327061, 0.002918903, 0.0038223783, 0.00...  0.515646     9","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw_data</th>\n      <th>duration</th>\n      <th>digit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[-0.00035317737, -0.0003979482, -0.00042274845...</td>\n      <td>0.442540</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[0.000108883556, 0.00013303479, 0.00024854412,...</td>\n      <td>0.386757</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0.0017647212, 0.0026649828, 0.0028954616, 0.0...</td>\n      <td>0.452789</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[5.169994e-05, 6.9254784e-05, 6.970848e-05, 6....</td>\n      <td>0.366893</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[0.0019327061, 0.002918903, 0.0038223783, 0.00...</td>\n      <td>0.515646</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data[['raw_data','duration']],data['digit'], test_size=0.3, random_state=45,stratify=data['digit'])","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:15:12.095334Z","iopub.execute_input":"2021-09-16T14:15:12.095619Z","iopub.status.idle":"2021-09-16T14:15:12.111636Z","shell.execute_reply.started":"2021-09-16T14:15:12.095585Z","shell.execute_reply":"2021-09-16T14:15:12.110924Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"for i in range(0,101,10):\n    print(i,' th percentile is ',np.percentile([len(i) for i in X_train['raw_data']],i))","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:15:12.112955Z","iopub.execute_input":"2021-09-16T14:15:12.113202Z","iopub.status.idle":"2021-09-16T14:15:12.140899Z","shell.execute_reply.started":"2021-09-16T14:15:12.113172Z","shell.execute_reply":"2021-09-16T14:15:12.140265Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"0  th percentile is  3165.0\n10  th percentile is  6074.8\n20  th percentile is  7179.2\n30  th percentile is  7879.199999999999\n40  th percentile is  8615.8\n50  th percentile is  9231.0\n60  th percentile is  9929.8\n70  th percentile is  10744.4\n80  th percentile is  11726.0\n90  th percentile is  13377.000000000004\n100  th percentile is  48420.0\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(90,101,1):\n    print(i,' th percentile is ',np.percentile([len(i) for i in X_train['raw_data']],i))","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:15:12.143558Z","iopub.execute_input":"2021-09-16T14:15:12.143751Z","iopub.status.idle":"2021-09-16T14:15:12.168691Z","shell.execute_reply.started":"2021-09-16T14:15:12.143729Z","shell.execute_reply":"2021-09-16T14:15:12.168081Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"90  th percentile is  13377.000000000004\n91  th percentile is  13603.0\n92  th percentile is  13804.880000000001\n93  th percentile is  14066.910000000003\n94  th percentile is  14298.8\n95  th percentile is  14658.55\n96  th percentile is  15069.32\n97  th percentile is  15816.99\n98  th percentile is  17488.04\n99  th percentile is  20366.199999999997\n100  th percentile is  48420.0\n","output_type":"stream"}]},{"cell_type":"code","source":"max_length=20366","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:15:12.170865Z","iopub.execute_input":"2021-09-16T14:15:12.171107Z","iopub.status.idle":"2021-09-16T14:15:12.175532Z","shell.execute_reply.started":"2021-09-16T14:15:12.171078Z","shell.execute_reply":"2021-09-16T14:15:12.174748Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### We are padding the sequence as we going to use LSTM","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nX_train_pad=tf.keras.preprocessing.sequence.pad_sequences(X_train['raw_data'],maxlen=max_length, dtype='float32')\nX_test_pad=tf.keras.preprocessing.sequence.pad_sequences(X_test['raw_data'],maxlen=max_length, dtype='float32')\nX_train_mask=np.where(X_train_pad>0.0,True,False)\nX_test_mask=np.where(X_test_pad>0.0,True,False)","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:15:12.176711Z","iopub.execute_input":"2021-09-16T14:15:12.177114Z","iopub.status.idle":"2021-09-16T14:15:16.020580Z","shell.execute_reply.started":"2021-09-16T14:15:12.177078Z","shell.execute_reply":"2021-09-16T14:15:16.019795Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, LSTM, Dense\nfrom tensorflow.keras.models import Model\nfrom sklearn.metrics import f1_score","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:15:16.023533Z","iopub.execute_input":"2021-09-16T14:15:16.023808Z","iopub.status.idle":"2021-09-16T14:15:16.028834Z","shell.execute_reply.started":"2021-09-16T14:15:16.023775Z","shell.execute_reply":"2021-09-16T14:15:16.027102Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Fourier Tranformation is computed on overlapping windowed segments of the signal, and we get what is called the spectrogram\n### Hence we are converting our raw_data ie time series to spectogram\n### Mel spectrogram is a spectrogram where the frequencies are converted to the mel scale","metadata":{}},{"cell_type":"code","source":"def convert_to_spectrogram(raw_data):\n    '''converting to spectrogram'''\n    spect = librosa.feature.melspectrogram(y=raw_data, n_mels=64) # n_mels as output shape\n    mel_spect = librosa.power_to_db(S=spect, ref=np.max)\n    return mel_spect","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:15:16.030195Z","iopub.execute_input":"2021-09-16T14:15:16.030451Z","iopub.status.idle":"2021-09-16T14:15:16.037843Z","shell.execute_reply.started":"2021-09-16T14:15:16.030417Z","shell.execute_reply":"2021-09-16T14:15:16.037117Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"X_train_spectrogram=np.array([convert_to_spectrogram(np.array([float(i) for i in X_train_pad[k] ])) for k in range(len(X_train_pad)) ])\nX_test_spectrogram=np.array([convert_to_spectrogram(np.array([float(i) for i in X_test_pad[k] ])) for k in range(len(X_test_pad)) ])","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:15:16.039186Z","iopub.execute_input":"2021-09-16T14:15:16.039488Z","iopub.status.idle":"2021-09-16T14:16:17.539959Z","shell.execute_reply.started":"2021-09-16T14:15:16.039445Z","shell.execute_reply":"2021-09-16T14:16:17.539076Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"X_train_spectrogram.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:16:17.541394Z","iopub.execute_input":"2021-09-16T14:16:17.541855Z","iopub.status.idle":"2021-09-16T14:16:17.547762Z","shell.execute_reply.started":"2021-09-16T14:16:17.541820Z","shell.execute_reply":"2021-09-16T14:16:17.547048Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(2100, 64, 40)"},"metadata":{}}]},{"cell_type":"code","source":"input_layer=Input(shape=(64,40), dtype=np.float32,name='input_layer')\nlstm=LSTM(500,name='lstm_layer',return_sequences=True)(input_layer)\nd1=Dense(120,activation='relu',name='dense1')(tf.math.reduce_mean(lstm, 2))\nd2=Dense(60,activation='relu',name='dense2')(d1)\nd3=Dense(10,activation='softmax',name='dense3')(d2)","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:16:17.549209Z","iopub.execute_input":"2021-09-16T14:16:17.549721Z","iopub.status.idle":"2021-09-16T14:16:19.827184Z","shell.execute_reply.started":"2021-09-16T14:16:17.549682Z","shell.execute_reply":"2021-09-16T14:16:19.826441Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model = Model(inputs=input_layer, outputs=d3)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:16:19.828516Z","iopub.execute_input":"2021-09-16T14:16:19.828782Z","iopub.status.idle":"2021-09-16T14:16:19.843543Z","shell.execute_reply.started":"2021-09-16T14:16:19.828751Z","shell.execute_reply":"2021-09-16T14:16:19.842431Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_layer (InputLayer)     [(None, 64, 40)]          0         \n_________________________________________________________________\nlstm_layer (LSTM)            (None, 64, 500)           1082000   \n_________________________________________________________________\ntf.math.reduce_mean (TFOpLam (None, 64)                0         \n_________________________________________________________________\ndense1 (Dense)               (None, 120)               7800      \n_________________________________________________________________\ndense2 (Dense)               (None, 60)                7260      \n_________________________________________________________________\ndense3 (Dense)               (None, 10)                610       \n=================================================================\nTotal params: 1,097,670\nTrainable params: 1,097,670\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"def cal_f1(y_true,y_pred):\n    return f1_score(y_true,y_pred,average='micro')\ndef micro_f1(y_true,y_prob):\n    y_pred=tf.math.argmax(y_prob,axis=1)\n    return tf.py_function(cal_f1,(y_true,y_pred),tf.double)","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:16:19.845411Z","iopub.execute_input":"2021-09-16T14:16:19.845847Z","iopub.status.idle":"2021-09-16T14:16:19.850832Z","shell.execute_reply.started":"2021-09-16T14:16:19.845812Z","shell.execute_reply":"2021-09-16T14:16:19.850051Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class LossHistory(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if logs.get('val_micro_f1', -1)>0.97:\n            self.model.stop_training=True\n\nloss_history=LossHistory()\n\nfilepath=\"model_save/weights-{epoch:02d}-{micro_f1:.4f}-{val_micro_f1:.4f}.hdf5\"\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath, monitor='val_micro_f1',  verbose=1, save_best_only=True, mode='max')","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:16:19.852595Z","iopub.execute_input":"2021-09-16T14:16:19.853311Z","iopub.status.idle":"2021-09-16T14:16:19.860518Z","shell.execute_reply.started":"2021-09-16T14:16:19.853275Z","shell.execute_reply":"2021-09-16T14:16:19.859687Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"opt= tf.keras.optimizers.Adam(learning_rate=0.001)\nmodel.compile(optimizer=opt, loss='sparse_categorical_crossentropy' ,metrics=['accuracy',micro_f1])","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:16:19.861965Z","iopub.execute_input":"2021-09-16T14:16:19.862221Z","iopub.status.idle":"2021-09-16T14:16:19.879945Z","shell.execute_reply.started":"2021-09-16T14:16:19.862190Z","shell.execute_reply":"2021-09-16T14:16:19.879037Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\nmodel.fit(X_train_spectrogram,y_train.astype('int')\\\n           ,validation_data=(X_test_spectrogram,y_test.astype('int'))\\\n           ,batch_size=32,epochs=400\\\n           ,callbacks=[loss_history,checkpoint])","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:16:19.881504Z","iopub.execute_input":"2021-09-16T14:16:19.881848Z","iopub.status.idle":"2021-09-16T14:23:44.478443Z","shell.execute_reply.started":"2021-09-16T14:16:19.881811Z","shell.execute_reply":"2021-09-16T14:23:44.477771Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1/400\n66/66 [==============================] - 9s 28ms/step - loss: 2.2961 - accuracy: 0.1018 - micro_f1: 0.1018 - val_loss: 2.1567 - val_accuracy: 0.2567 - val_micro_f1: 0.2640\n\nEpoch 00001: val_micro_f1 improved from -inf to 0.26401, saving model to model_save/weights-01-0.1330-0.2640.hdf5\nEpoch 2/400\n66/66 [==============================] - 1s 16ms/step - loss: 2.0053 - accuracy: 0.3159 - micro_f1: 0.3159 - val_loss: 1.6783 - val_accuracy: 0.3533 - val_micro_f1: 0.3578\n\nEpoch 00002: val_micro_f1 improved from 0.26401 to 0.35776, saving model to model_save/weights-02-0.3346-0.3578.hdf5\nEpoch 3/400\n66/66 [==============================] - 1s 16ms/step - loss: 1.5598 - accuracy: 0.4090 - micro_f1: 0.4090 - val_loss: 1.4002 - val_accuracy: 0.4800 - val_micro_f1: 0.4655\n\nEpoch 00003: val_micro_f1 improved from 0.35776 to 0.46552, saving model to model_save/weights-03-0.4387-0.4655.hdf5\nEpoch 4/400\n66/66 [==============================] - 1s 16ms/step - loss: 1.3964 - accuracy: 0.5023 - micro_f1: 0.5023 - val_loss: 1.3333 - val_accuracy: 0.5244 - val_micro_f1: 0.5086\n\nEpoch 00004: val_micro_f1 improved from 0.46552 to 0.50862, saving model to model_save/weights-04-0.4867-0.5086.hdf5\nEpoch 5/400\n66/66 [==============================] - 1s 16ms/step - loss: 1.2947 - accuracy: 0.5245 - micro_f1: 0.5245 - val_loss: 1.2801 - val_accuracy: 0.5644 - val_micro_f1: 0.5474\n\nEpoch 00005: val_micro_f1 improved from 0.50862 to 0.54741, saving model to model_save/weights-05-0.5225-0.5474.hdf5\nEpoch 6/400\n66/66 [==============================] - 1s 17ms/step - loss: 1.2498 - accuracy: 0.5497 - micro_f1: 0.5497 - val_loss: 1.1759 - val_accuracy: 0.5833 - val_micro_f1: 0.5657\n\nEpoch 00006: val_micro_f1 improved from 0.54741 to 0.56573, saving model to model_save/weights-06-0.5540-0.5657.hdf5\nEpoch 7/400\n66/66 [==============================] - 1s 17ms/step - loss: 1.1790 - accuracy: 0.5548 - micro_f1: 0.5548 - val_loss: 1.2029 - val_accuracy: 0.5789 - val_micro_f1: 0.5614\n\nEpoch 00007: val_micro_f1 did not improve from 0.56573\nEpoch 8/400\n66/66 [==============================] - 1s 16ms/step - loss: 1.1502 - accuracy: 0.5919 - micro_f1: 0.5919 - val_loss: 1.1113 - val_accuracy: 0.6267 - val_micro_f1: 0.6078\n\nEpoch 00008: val_micro_f1 improved from 0.56573 to 0.60776, saving model to model_save/weights-08-0.5840-0.6078.hdf5\nEpoch 9/400\n66/66 [==============================] - 1s 16ms/step - loss: 1.0774 - accuracy: 0.6157 - micro_f1: 0.6156 - val_loss: 1.0632 - val_accuracy: 0.6089 - val_micro_f1: 0.5905\n\nEpoch 00009: val_micro_f1 did not improve from 0.60776\nEpoch 10/400\n66/66 [==============================] - 1s 16ms/step - loss: 1.0783 - accuracy: 0.5968 - micro_f1: 0.5968 - val_loss: 1.0165 - val_accuracy: 0.6511 - val_micro_f1: 0.6390\n\nEpoch 00010: val_micro_f1 improved from 0.60776 to 0.63901, saving model to model_save/weights-10-0.6219-0.6390.hdf5\nEpoch 11/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.9981 - accuracy: 0.6244 - micro_f1: 0.6244 - val_loss: 0.9786 - val_accuracy: 0.6322 - val_micro_f1: 0.6131\n\nEpoch 00011: val_micro_f1 did not improve from 0.63901\nEpoch 12/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.9444 - accuracy: 0.6572 - micro_f1: 0.6572 - val_loss: 0.9310 - val_accuracy: 0.6578 - val_micro_f1: 0.6379\n\nEpoch 00012: val_micro_f1 did not improve from 0.63901\nEpoch 13/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.9102 - accuracy: 0.6773 - micro_f1: 0.6773 - val_loss: 0.8832 - val_accuracy: 0.6844 - val_micro_f1: 0.6638\n\nEpoch 00013: val_micro_f1 improved from 0.63901 to 0.66379, saving model to model_save/weights-13-0.6673-0.6638.hdf5\nEpoch 14/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.8440 - accuracy: 0.6950 - micro_f1: 0.6950 - val_loss: 0.8479 - val_accuracy: 0.7100 - val_micro_f1: 0.6886\n\nEpoch 00014: val_micro_f1 improved from 0.66379 to 0.68858, saving model to model_save/weights-14-0.6813-0.6886.hdf5\nEpoch 15/400\n66/66 [==============================] - 1s 20ms/step - loss: 0.8529 - accuracy: 0.6835 - micro_f1: 0.6835 - val_loss: 0.8091 - val_accuracy: 0.7233 - val_micro_f1: 0.7166\n\nEpoch 00015: val_micro_f1 improved from 0.68858 to 0.71659, saving model to model_save/weights-15-0.6903-0.7166.hdf5\nEpoch 16/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.7802 - accuracy: 0.7130 - micro_f1: 0.7130 - val_loss: 0.7769 - val_accuracy: 0.7211 - val_micro_f1: 0.7069\n\nEpoch 00016: val_micro_f1 did not improve from 0.71659\nEpoch 17/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.7824 - accuracy: 0.7220 - micro_f1: 0.7220 - val_loss: 0.7881 - val_accuracy: 0.7411 - val_micro_f1: 0.7188\n\nEpoch 00017: val_micro_f1 improved from 0.71659 to 0.71875, saving model to model_save/weights-17-0.7291-0.7188.hdf5\nEpoch 18/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.7733 - accuracy: 0.7095 - micro_f1: 0.7095 - val_loss: 0.7289 - val_accuracy: 0.7300 - val_micro_f1: 0.7306\n\nEpoch 00018: val_micro_f1 improved from 0.71875 to 0.73060, saving model to model_save/weights-18-0.7200-0.7306.hdf5\nEpoch 19/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.7515 - accuracy: 0.7261 - micro_f1: 0.7261 - val_loss: 0.7349 - val_accuracy: 0.7389 - val_micro_f1: 0.7241\n\nEpoch 00019: val_micro_f1 did not improve from 0.73060\nEpoch 20/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.7103 - accuracy: 0.7590 - micro_f1: 0.7590 - val_loss: 0.7136 - val_accuracy: 0.7556 - val_micro_f1: 0.7478\n\nEpoch 00020: val_micro_f1 improved from 0.73060 to 0.74784, saving model to model_save/weights-20-0.7500-0.7478.hdf5\nEpoch 21/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.6857 - accuracy: 0.7506 - micro_f1: 0.7505 - val_loss: 0.6822 - val_accuracy: 0.7622 - val_micro_f1: 0.7543\n\nEpoch 00021: val_micro_f1 improved from 0.74784 to 0.75431, saving model to model_save/weights-21-0.7491-0.7543.hdf5\nEpoch 22/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.6808 - accuracy: 0.7563 - micro_f1: 0.7563 - val_loss: 0.7452 - val_accuracy: 0.7300 - val_micro_f1: 0.7231\n\nEpoch 00022: val_micro_f1 did not improve from 0.75431\nEpoch 23/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.6960 - accuracy: 0.7431 - micro_f1: 0.7431 - val_loss: 0.6483 - val_accuracy: 0.7744 - val_micro_f1: 0.7737\n\nEpoch 00023: val_micro_f1 improved from 0.75431 to 0.77371, saving model to model_save/weights-23-0.7664-0.7737.hdf5\nEpoch 24/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.6298 - accuracy: 0.7795 - micro_f1: 0.7795 - val_loss: 0.6400 - val_accuracy: 0.7767 - val_micro_f1: 0.7683\n\nEpoch 00024: val_micro_f1 did not improve from 0.77371\nEpoch 25/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.6175 - accuracy: 0.7791 - micro_f1: 0.7791 - val_loss: 0.6265 - val_accuracy: 0.7856 - val_micro_f1: 0.7845\n\nEpoch 00025: val_micro_f1 improved from 0.77371 to 0.78448, saving model to model_save/weights-25-0.7784-0.7845.hdf5\nEpoch 26/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.6002 - accuracy: 0.7839 - micro_f1: 0.7839 - val_loss: 0.6571 - val_accuracy: 0.7678 - val_micro_f1: 0.7672\n\nEpoch 00026: val_micro_f1 did not improve from 0.78448\nEpoch 27/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.5943 - accuracy: 0.7924 - micro_f1: 0.7924 - val_loss: 0.6209 - val_accuracy: 0.7789 - val_micro_f1: 0.7856\n\nEpoch 00027: val_micro_f1 improved from 0.78448 to 0.78556, saving model to model_save/weights-27-0.7891-0.7856.hdf5\nEpoch 28/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.5929 - accuracy: 0.7854 - micro_f1: 0.7854 - val_loss: 0.5814 - val_accuracy: 0.8011 - val_micro_f1: 0.8071\n\nEpoch 00028: val_micro_f1 improved from 0.78556 to 0.80711, saving model to model_save/weights-28-0.7916-0.8071.hdf5\nEpoch 29/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.5404 - accuracy: 0.8223 - micro_f1: 0.8222 - val_loss: 0.5760 - val_accuracy: 0.8022 - val_micro_f1: 0.8082\n\nEpoch 00029: val_micro_f1 improved from 0.80711 to 0.80819, saving model to model_save/weights-29-0.8078-0.8082.hdf5\nEpoch 30/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.5427 - accuracy: 0.8193 - micro_f1: 0.8193 - val_loss: 0.6194 - val_accuracy: 0.7844 - val_micro_f1: 0.7834\n\nEpoch 00030: val_micro_f1 did not improve from 0.80819\nEpoch 31/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.5202 - accuracy: 0.8182 - micro_f1: 0.8182 - val_loss: 0.5516 - val_accuracy: 0.8144 - val_micro_f1: 0.8200\n\nEpoch 00031: val_micro_f1 improved from 0.80819 to 0.82004, saving model to model_save/weights-31-0.8156-0.8200.hdf5\nEpoch 32/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.5119 - accuracy: 0.8299 - micro_f1: 0.8299 - val_loss: 0.5607 - val_accuracy: 0.8133 - val_micro_f1: 0.8114\n\nEpoch 00032: val_micro_f1 did not improve from 0.82004\nEpoch 33/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.5099 - accuracy: 0.8266 - micro_f1: 0.8266 - val_loss: 0.5980 - val_accuracy: 0.7878 - val_micro_f1: 0.7866\n\nEpoch 00033: val_micro_f1 did not improve from 0.82004\nEpoch 34/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.5455 - accuracy: 0.8156 - micro_f1: 0.8156 - val_loss: 0.6121 - val_accuracy: 0.7789 - val_micro_f1: 0.7780\n\nEpoch 00034: val_micro_f1 did not improve from 0.82004\nEpoch 35/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.5241 - accuracy: 0.8207 - micro_f1: 0.8207 - val_loss: 0.5454 - val_accuracy: 0.8222 - val_micro_f1: 0.8125\n\nEpoch 00035: val_micro_f1 did not improve from 0.82004\nEpoch 36/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.5237 - accuracy: 0.8141 - micro_f1: 0.8141 - val_loss: 0.5598 - val_accuracy: 0.8078 - val_micro_f1: 0.7985\n\nEpoch 00036: val_micro_f1 did not improve from 0.82004\nEpoch 37/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.4751 - accuracy: 0.8339 - micro_f1: 0.8339 - val_loss: 0.5557 - val_accuracy: 0.8256 - val_micro_f1: 0.8233\n\nEpoch 00037: val_micro_f1 improved from 0.82004 to 0.82328, saving model to model_save/weights-37-0.8358-0.8233.hdf5\nEpoch 38/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.4899 - accuracy: 0.8275 - micro_f1: 0.8275 - val_loss: 0.5332 - val_accuracy: 0.8022 - val_micro_f1: 0.8006\n\nEpoch 00038: val_micro_f1 did not improve from 0.82328\nEpoch 39/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.4759 - accuracy: 0.8496 - micro_f1: 0.8496 - val_loss: 0.5429 - val_accuracy: 0.8178 - val_micro_f1: 0.8157\n\nEpoch 00039: val_micro_f1 did not improve from 0.82328\nEpoch 40/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.4871 - accuracy: 0.8353 - micro_f1: 0.8353 - val_loss: 0.5425 - val_accuracy: 0.8300 - val_micro_f1: 0.8351\n\nEpoch 00040: val_micro_f1 improved from 0.82328 to 0.83513, saving model to model_save/weights-40-0.8472-0.8351.hdf5\nEpoch 41/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.4449 - accuracy: 0.8592 - micro_f1: 0.8593 - val_loss: 0.4882 - val_accuracy: 0.8211 - val_micro_f1: 0.8265\n\nEpoch 00041: val_micro_f1 did not improve from 0.83513\nEpoch 42/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.4290 - accuracy: 0.8637 - micro_f1: 0.8637 - val_loss: 0.5097 - val_accuracy: 0.8256 - val_micro_f1: 0.8233\n\nEpoch 00042: val_micro_f1 did not improve from 0.83513\nEpoch 43/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.4768 - accuracy: 0.8315 - micro_f1: 0.8315 - val_loss: 0.5088 - val_accuracy: 0.8256 - val_micro_f1: 0.8082\n\nEpoch 00043: val_micro_f1 did not improve from 0.83513\nEpoch 44/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.4631 - accuracy: 0.8384 - micro_f1: 0.8384 - val_loss: 0.4927 - val_accuracy: 0.8389 - val_micro_f1: 0.8362\n\nEpoch 00044: val_micro_f1 improved from 0.83513 to 0.83621, saving model to model_save/weights-44-0.8394-0.8362.hdf5\nEpoch 45/400\n66/66 [==============================] - 1s 19ms/step - loss: 0.4218 - accuracy: 0.8787 - micro_f1: 0.8787 - val_loss: 0.4838 - val_accuracy: 0.8167 - val_micro_f1: 0.8147\n\nEpoch 00045: val_micro_f1 did not improve from 0.83621\nEpoch 46/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.4045 - accuracy: 0.8666 - micro_f1: 0.8666 - val_loss: 0.4749 - val_accuracy: 0.8433 - val_micro_f1: 0.8405\n\nEpoch 00046: val_micro_f1 improved from 0.83621 to 0.84052, saving model to model_save/weights-46-0.8552-0.8405.hdf5\nEpoch 47/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3892 - accuracy: 0.8645 - micro_f1: 0.8645 - val_loss: 0.4971 - val_accuracy: 0.8378 - val_micro_f1: 0.8427\n\nEpoch 00047: val_micro_f1 improved from 0.84052 to 0.84267, saving model to model_save/weights-47-0.8587-0.8427.hdf5\nEpoch 48/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.3877 - accuracy: 0.8765 - micro_f1: 0.8765 - val_loss: 0.4674 - val_accuracy: 0.8378 - val_micro_f1: 0.8427\n\nEpoch 00048: val_micro_f1 did not improve from 0.84267\nEpoch 49/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3944 - accuracy: 0.8693 - micro_f1: 0.8692 - val_loss: 0.4622 - val_accuracy: 0.8444 - val_micro_f1: 0.8416\n\nEpoch 00049: val_micro_f1 did not improve from 0.84267\nEpoch 50/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.4136 - accuracy: 0.8667 - micro_f1: 0.8667 - val_loss: 0.4998 - val_accuracy: 0.8333 - val_micro_f1: 0.8308\n\nEpoch 00050: val_micro_f1 did not improve from 0.84267\nEpoch 51/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.4261 - accuracy: 0.8555 - micro_f1: 0.8555 - val_loss: 0.4400 - val_accuracy: 0.8467 - val_micro_f1: 0.8438\n\nEpoch 00051: val_micro_f1 improved from 0.84267 to 0.84375, saving model to model_save/weights-51-0.8658-0.8438.hdf5\nEpoch 52/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.4021 - accuracy: 0.8735 - micro_f1: 0.8735 - val_loss: 0.4495 - val_accuracy: 0.8478 - val_micro_f1: 0.8448\n\nEpoch 00052: val_micro_f1 improved from 0.84375 to 0.84483, saving model to model_save/weights-52-0.8776-0.8448.hdf5\nEpoch 53/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3828 - accuracy: 0.8696 - micro_f1: 0.8697 - val_loss: 0.4562 - val_accuracy: 0.8444 - val_micro_f1: 0.8491\n\nEpoch 00053: val_micro_f1 improved from 0.84483 to 0.84914, saving model to model_save/weights-53-0.8815-0.8491.hdf5\nEpoch 54/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.4128 - accuracy: 0.8674 - micro_f1: 0.8675 - val_loss: 0.4527 - val_accuracy: 0.8378 - val_micro_f1: 0.8427\n\nEpoch 00054: val_micro_f1 did not improve from 0.84914\nEpoch 55/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3797 - accuracy: 0.8781 - micro_f1: 0.8781 - val_loss: 0.4344 - val_accuracy: 0.8489 - val_micro_f1: 0.8459\n\nEpoch 00055: val_micro_f1 did not improve from 0.84914\nEpoch 56/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.3649 - accuracy: 0.8871 - micro_f1: 0.8871 - val_loss: 0.5001 - val_accuracy: 0.8433 - val_micro_f1: 0.8405\n\nEpoch 00056: val_micro_f1 did not improve from 0.84914\nEpoch 57/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3928 - accuracy: 0.8756 - micro_f1: 0.8756 - val_loss: 0.4576 - val_accuracy: 0.8389 - val_micro_f1: 0.8362\n\nEpoch 00057: val_micro_f1 did not improve from 0.84914\nEpoch 58/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.3751 - accuracy: 0.8713 - micro_f1: 0.8713 - val_loss: 0.4107 - val_accuracy: 0.8589 - val_micro_f1: 0.8631\n\nEpoch 00058: val_micro_f1 improved from 0.84914 to 0.86315, saving model to model_save/weights-58-0.8756-0.8631.hdf5\nEpoch 59/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3584 - accuracy: 0.8916 - micro_f1: 0.8916 - val_loss: 0.4526 - val_accuracy: 0.8522 - val_micro_f1: 0.8567\n\nEpoch 00059: val_micro_f1 did not improve from 0.86315\nEpoch 60/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3615 - accuracy: 0.8880 - micro_f1: 0.8880 - val_loss: 0.4486 - val_accuracy: 0.8411 - val_micro_f1: 0.8459\n\nEpoch 00060: val_micro_f1 did not improve from 0.86315\nEpoch 61/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3334 - accuracy: 0.9009 - micro_f1: 0.9009 - val_loss: 0.4544 - val_accuracy: 0.8500 - val_micro_f1: 0.8545\n\nEpoch 00061: val_micro_f1 did not improve from 0.86315\nEpoch 62/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3960 - accuracy: 0.8824 - micro_f1: 0.8824 - val_loss: 0.4433 - val_accuracy: 0.8344 - val_micro_f1: 0.8319\n\nEpoch 00062: val_micro_f1 did not improve from 0.86315\nEpoch 63/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3416 - accuracy: 0.8932 - micro_f1: 0.8932 - val_loss: 0.3934 - val_accuracy: 0.8622 - val_micro_f1: 0.8513\n\nEpoch 00063: val_micro_f1 did not improve from 0.86315\nEpoch 64/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3571 - accuracy: 0.8748 - micro_f1: 0.8748 - val_loss: 0.4169 - val_accuracy: 0.8478 - val_micro_f1: 0.8524\n\nEpoch 00064: val_micro_f1 did not improve from 0.86315\nEpoch 65/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3200 - accuracy: 0.9047 - micro_f1: 0.9047 - val_loss: 0.4546 - val_accuracy: 0.8511 - val_micro_f1: 0.8481\n\nEpoch 00065: val_micro_f1 did not improve from 0.86315\nEpoch 66/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.3675 - accuracy: 0.8780 - micro_f1: 0.8780 - val_loss: 0.3956 - val_accuracy: 0.8711 - val_micro_f1: 0.8750\n\nEpoch 00066: val_micro_f1 improved from 0.86315 to 0.87500, saving model to model_save/weights-66-0.8912-0.8750.hdf5\nEpoch 67/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3313 - accuracy: 0.8829 - micro_f1: 0.8829 - val_loss: 0.3972 - val_accuracy: 0.8711 - val_micro_f1: 0.8750\n\nEpoch 00067: val_micro_f1 did not improve from 0.87500\nEpoch 68/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3263 - accuracy: 0.8966 - micro_f1: 0.8966 - val_loss: 0.4129 - val_accuracy: 0.8522 - val_micro_f1: 0.8567\n\nEpoch 00068: val_micro_f1 did not improve from 0.87500\nEpoch 69/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3615 - accuracy: 0.8876 - micro_f1: 0.8876 - val_loss: 0.4095 - val_accuracy: 0.8600 - val_micro_f1: 0.8567\n\nEpoch 00069: val_micro_f1 did not improve from 0.87500\nEpoch 70/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3696 - accuracy: 0.8760 - micro_f1: 0.8760 - val_loss: 0.4114 - val_accuracy: 0.8544 - val_micro_f1: 0.8513\n\nEpoch 00070: val_micro_f1 did not improve from 0.87500\nEpoch 71/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3153 - accuracy: 0.8999 - micro_f1: 0.8998 - val_loss: 0.4122 - val_accuracy: 0.8522 - val_micro_f1: 0.8416\n\nEpoch 00071: val_micro_f1 did not improve from 0.87500\nEpoch 72/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3410 - accuracy: 0.8872 - micro_f1: 0.8872 - val_loss: 0.4109 - val_accuracy: 0.8467 - val_micro_f1: 0.8513\n\nEpoch 00072: val_micro_f1 did not improve from 0.87500\nEpoch 73/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3242 - accuracy: 0.8934 - micro_f1: 0.8934 - val_loss: 0.4023 - val_accuracy: 0.8511 - val_micro_f1: 0.8481\n\nEpoch 00073: val_micro_f1 did not improve from 0.87500\nEpoch 74/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3053 - accuracy: 0.8969 - micro_f1: 0.8969 - val_loss: 0.4526 - val_accuracy: 0.8411 - val_micro_f1: 0.8384\n\nEpoch 00074: val_micro_f1 did not improve from 0.87500\nEpoch 75/400\n66/66 [==============================] - 1s 20ms/step - loss: 0.3209 - accuracy: 0.8932 - micro_f1: 0.8932 - val_loss: 0.3795 - val_accuracy: 0.8633 - val_micro_f1: 0.8599\n\nEpoch 00075: val_micro_f1 did not improve from 0.87500\nEpoch 76/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.3140 - accuracy: 0.8930 - micro_f1: 0.8930 - val_loss: 0.4129 - val_accuracy: 0.8522 - val_micro_f1: 0.8491\n\nEpoch 00076: val_micro_f1 did not improve from 0.87500\nEpoch 77/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3172 - accuracy: 0.8961 - micro_f1: 0.8961 - val_loss: 0.3877 - val_accuracy: 0.8656 - val_micro_f1: 0.8621\n\nEpoch 00077: val_micro_f1 did not improve from 0.87500\nEpoch 78/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3078 - accuracy: 0.8968 - micro_f1: 0.8968 - val_loss: 0.3870 - val_accuracy: 0.8567 - val_micro_f1: 0.8610\n\nEpoch 00078: val_micro_f1 did not improve from 0.87500\nEpoch 79/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3353 - accuracy: 0.8867 - micro_f1: 0.8867 - val_loss: 0.4188 - val_accuracy: 0.8533 - val_micro_f1: 0.8578\n\nEpoch 00079: val_micro_f1 did not improve from 0.87500\nEpoch 80/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3199 - accuracy: 0.8880 - micro_f1: 0.8880 - val_loss: 0.3913 - val_accuracy: 0.8622 - val_micro_f1: 0.8513\n\nEpoch 00080: val_micro_f1 did not improve from 0.87500\nEpoch 81/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3096 - accuracy: 0.9040 - micro_f1: 0.9040 - val_loss: 0.4031 - val_accuracy: 0.8556 - val_micro_f1: 0.8524\n\nEpoch 00081: val_micro_f1 did not improve from 0.87500\nEpoch 82/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3367 - accuracy: 0.8893 - micro_f1: 0.8893 - val_loss: 0.3799 - val_accuracy: 0.8633 - val_micro_f1: 0.8599\n\nEpoch 00082: val_micro_f1 did not improve from 0.87500\nEpoch 83/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.2967 - accuracy: 0.9065 - micro_f1: 0.9065 - val_loss: 0.4099 - val_accuracy: 0.8522 - val_micro_f1: 0.8491\n\nEpoch 00083: val_micro_f1 did not improve from 0.87500\nEpoch 84/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.2889 - accuracy: 0.9052 - micro_f1: 0.9051 - val_loss: 0.3902 - val_accuracy: 0.8700 - val_micro_f1: 0.8739\n\nEpoch 00084: val_micro_f1 did not improve from 0.87500\nEpoch 85/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.2899 - accuracy: 0.9094 - micro_f1: 0.9094 - val_loss: 0.3617 - val_accuracy: 0.8856 - val_micro_f1: 0.8890\n\nEpoch 00085: val_micro_f1 improved from 0.87500 to 0.88901, saving model to model_save/weights-85-0.9083-0.8890.hdf5\nEpoch 86/400\n66/66 [==============================] - 1s 19ms/step - loss: 0.2795 - accuracy: 0.9155 - micro_f1: 0.9155 - val_loss: 0.3611 - val_accuracy: 0.8733 - val_micro_f1: 0.8696\n\nEpoch 00086: val_micro_f1 did not improve from 0.88901\nEpoch 87/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.2650 - accuracy: 0.9162 - micro_f1: 0.9162 - val_loss: 0.3941 - val_accuracy: 0.8589 - val_micro_f1: 0.8631\n\nEpoch 00087: val_micro_f1 did not improve from 0.88901\nEpoch 88/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.3113 - accuracy: 0.9052 - micro_f1: 0.9052 - val_loss: 0.4467 - val_accuracy: 0.8422 - val_micro_f1: 0.8470\n\nEpoch 00088: val_micro_f1 did not improve from 0.88901\nEpoch 89/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3102 - accuracy: 0.9021 - micro_f1: 0.9021 - val_loss: 0.3600 - val_accuracy: 0.8700 - val_micro_f1: 0.8739\n\nEpoch 00089: val_micro_f1 did not improve from 0.88901\nEpoch 90/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.3096 - accuracy: 0.9038 - micro_f1: 0.9038 - val_loss: 0.3686 - val_accuracy: 0.8778 - val_micro_f1: 0.8739\n\nEpoch 00090: val_micro_f1 did not improve from 0.88901\nEpoch 91/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2913 - accuracy: 0.9087 - micro_f1: 0.9087 - val_loss: 0.3712 - val_accuracy: 0.8789 - val_micro_f1: 0.8750\n\nEpoch 00091: val_micro_f1 did not improve from 0.88901\nEpoch 92/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2898 - accuracy: 0.9034 - micro_f1: 0.9034 - val_loss: 0.3703 - val_accuracy: 0.8667 - val_micro_f1: 0.8631\n\nEpoch 00092: val_micro_f1 did not improve from 0.88901\nEpoch 93/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2841 - accuracy: 0.9111 - micro_f1: 0.9111 - val_loss: 0.3713 - val_accuracy: 0.8744 - val_micro_f1: 0.8707\n\nEpoch 00093: val_micro_f1 did not improve from 0.88901\nEpoch 94/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2772 - accuracy: 0.9050 - micro_f1: 0.9050 - val_loss: 0.3457 - val_accuracy: 0.8878 - val_micro_f1: 0.8912\n\nEpoch 00094: val_micro_f1 improved from 0.88901 to 0.89116, saving model to model_save/weights-94-0.9073-0.8912.hdf5\nEpoch 95/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2463 - accuracy: 0.9139 - micro_f1: 0.9139 - val_loss: 0.4459 - val_accuracy: 0.8344 - val_micro_f1: 0.8319\n\nEpoch 00095: val_micro_f1 did not improve from 0.89116\nEpoch 96/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.2727 - accuracy: 0.9098 - micro_f1: 0.9098 - val_loss: 0.3371 - val_accuracy: 0.8878 - val_micro_f1: 0.8836\n\nEpoch 00096: val_micro_f1 did not improve from 0.89116\nEpoch 97/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2634 - accuracy: 0.9152 - micro_f1: 0.9152 - val_loss: 0.3346 - val_accuracy: 0.8911 - val_micro_f1: 0.8869\n\nEpoch 00097: val_micro_f1 did not improve from 0.89116\nEpoch 98/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2808 - accuracy: 0.9027 - micro_f1: 0.9027 - val_loss: 0.3518 - val_accuracy: 0.8811 - val_micro_f1: 0.8696\n\nEpoch 00098: val_micro_f1 did not improve from 0.89116\nEpoch 99/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2590 - accuracy: 0.9109 - micro_f1: 0.9109 - val_loss: 0.3595 - val_accuracy: 0.8689 - val_micro_f1: 0.8653\n\nEpoch 00099: val_micro_f1 did not improve from 0.89116\nEpoch 100/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2928 - accuracy: 0.9083 - micro_f1: 0.9083 - val_loss: 0.3395 - val_accuracy: 0.8900 - val_micro_f1: 0.8933\n\nEpoch 00100: val_micro_f1 improved from 0.89116 to 0.89332, saving model to model_save/weights-100-0.9039-0.8933.hdf5\nEpoch 101/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2867 - accuracy: 0.8994 - micro_f1: 0.8994 - val_loss: 0.3646 - val_accuracy: 0.8844 - val_micro_f1: 0.8879\n\nEpoch 00101: val_micro_f1 did not improve from 0.89332\nEpoch 102/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2950 - accuracy: 0.8944 - micro_f1: 0.8944 - val_loss: 0.3551 - val_accuracy: 0.8811 - val_micro_f1: 0.8847\n\nEpoch 00102: val_micro_f1 did not improve from 0.89332\nEpoch 103/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2528 - accuracy: 0.9193 - micro_f1: 0.9193 - val_loss: 0.3591 - val_accuracy: 0.8856 - val_micro_f1: 0.8890\n\nEpoch 00103: val_micro_f1 did not improve from 0.89332\nEpoch 104/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2797 - accuracy: 0.9101 - micro_f1: 0.9101 - val_loss: 0.3491 - val_accuracy: 0.8767 - val_micro_f1: 0.8728\n\nEpoch 00104: val_micro_f1 did not improve from 0.89332\nEpoch 105/400\n66/66 [==============================] - 1s 20ms/step - loss: 0.2817 - accuracy: 0.9072 - micro_f1: 0.9072 - val_loss: 0.3321 - val_accuracy: 0.8944 - val_micro_f1: 0.8976\n\nEpoch 00105: val_micro_f1 improved from 0.89332 to 0.89763, saving model to model_save/weights-105-0.9079-0.8976.hdf5\nEpoch 106/400\n66/66 [==============================] - 1s 19ms/step - loss: 0.2664 - accuracy: 0.9141 - micro_f1: 0.9141 - val_loss: 0.3347 - val_accuracy: 0.8833 - val_micro_f1: 0.8869\n\nEpoch 00106: val_micro_f1 did not improve from 0.89763\nEpoch 107/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2289 - accuracy: 0.9262 - micro_f1: 0.9262 - val_loss: 0.3131 - val_accuracy: 0.8900 - val_micro_f1: 0.8933\n\nEpoch 00107: val_micro_f1 did not improve from 0.89763\nEpoch 108/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2323 - accuracy: 0.9287 - micro_f1: 0.9288 - val_loss: 0.3560 - val_accuracy: 0.8722 - val_micro_f1: 0.8685\n\nEpoch 00108: val_micro_f1 did not improve from 0.89763\nEpoch 109/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2757 - accuracy: 0.9118 - micro_f1: 0.9118 - val_loss: 0.3244 - val_accuracy: 0.8800 - val_micro_f1: 0.8761\n\nEpoch 00109: val_micro_f1 did not improve from 0.89763\nEpoch 110/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2278 - accuracy: 0.9236 - micro_f1: 0.9236 - val_loss: 0.3365 - val_accuracy: 0.8822 - val_micro_f1: 0.8782\n\nEpoch 00110: val_micro_f1 did not improve from 0.89763\nEpoch 111/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2543 - accuracy: 0.9195 - micro_f1: 0.9195 - val_loss: 0.3328 - val_accuracy: 0.8956 - val_micro_f1: 0.8987\n\nEpoch 00111: val_micro_f1 improved from 0.89763 to 0.89871, saving model to model_save/weights-111-0.9093-0.8987.hdf5\nEpoch 112/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2659 - accuracy: 0.9110 - micro_f1: 0.9110 - val_loss: 0.2906 - val_accuracy: 0.8978 - val_micro_f1: 0.9009\n\nEpoch 00112: val_micro_f1 improved from 0.89871 to 0.90086, saving model to model_save/weights-112-0.9170-0.9009.hdf5\nEpoch 113/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2426 - accuracy: 0.9328 - micro_f1: 0.9328 - val_loss: 0.3240 - val_accuracy: 0.8778 - val_micro_f1: 0.8739\n\nEpoch 00113: val_micro_f1 did not improve from 0.90086\nEpoch 114/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2342 - accuracy: 0.9323 - micro_f1: 0.9323 - val_loss: 0.3144 - val_accuracy: 0.8944 - val_micro_f1: 0.8976\n\nEpoch 00114: val_micro_f1 did not improve from 0.90086\nEpoch 115/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2392 - accuracy: 0.9175 - micro_f1: 0.9175 - val_loss: 0.3160 - val_accuracy: 0.8856 - val_micro_f1: 0.8815\n\nEpoch 00115: val_micro_f1 did not improve from 0.90086\nEpoch 116/400\n66/66 [==============================] - 1s 19ms/step - loss: 0.2354 - accuracy: 0.9278 - micro_f1: 0.9278 - val_loss: 0.3096 - val_accuracy: 0.8911 - val_micro_f1: 0.8944\n\nEpoch 00116: val_micro_f1 did not improve from 0.90086\nEpoch 117/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2296 - accuracy: 0.9207 - micro_f1: 0.9207 - val_loss: 0.2984 - val_accuracy: 0.9056 - val_micro_f1: 0.9084\n\nEpoch 00117: val_micro_f1 improved from 0.90086 to 0.90841, saving model to model_save/weights-117-0.9210-0.9084.hdf5\nEpoch 118/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2125 - accuracy: 0.9309 - micro_f1: 0.9309 - val_loss: 0.3723 - val_accuracy: 0.8678 - val_micro_f1: 0.8718\n\nEpoch 00118: val_micro_f1 did not improve from 0.90841\nEpoch 119/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2344 - accuracy: 0.9231 - micro_f1: 0.9231 - val_loss: 0.3153 - val_accuracy: 0.8967 - val_micro_f1: 0.8998\n\nEpoch 00119: val_micro_f1 did not improve from 0.90841\nEpoch 120/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2617 - accuracy: 0.9147 - micro_f1: 0.9147 - val_loss: 0.3840 - val_accuracy: 0.8633 - val_micro_f1: 0.8675\n\nEpoch 00120: val_micro_f1 did not improve from 0.90841\nEpoch 121/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2374 - accuracy: 0.9251 - micro_f1: 0.9251 - val_loss: 0.3352 - val_accuracy: 0.8822 - val_micro_f1: 0.8782\n\nEpoch 00121: val_micro_f1 did not improve from 0.90841\nEpoch 122/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2161 - accuracy: 0.9267 - micro_f1: 0.9267 - val_loss: 0.3321 - val_accuracy: 0.8833 - val_micro_f1: 0.8869\n\nEpoch 00122: val_micro_f1 did not improve from 0.90841\nEpoch 123/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2270 - accuracy: 0.9338 - micro_f1: 0.9338 - val_loss: 0.3494 - val_accuracy: 0.8789 - val_micro_f1: 0.8825\n\nEpoch 00123: val_micro_f1 did not improve from 0.90841\nEpoch 124/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2353 - accuracy: 0.9187 - micro_f1: 0.9187 - val_loss: 0.3594 - val_accuracy: 0.8656 - val_micro_f1: 0.8696\n\nEpoch 00124: val_micro_f1 did not improve from 0.90841\nEpoch 125/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2365 - accuracy: 0.9131 - micro_f1: 0.9131 - val_loss: 0.3197 - val_accuracy: 0.8811 - val_micro_f1: 0.8847\n\nEpoch 00125: val_micro_f1 did not improve from 0.90841\nEpoch 126/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.2181 - accuracy: 0.9327 - micro_f1: 0.9327 - val_loss: 0.3188 - val_accuracy: 0.8911 - val_micro_f1: 0.8944\n\nEpoch 00126: val_micro_f1 did not improve from 0.90841\nEpoch 127/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.2614 - accuracy: 0.9068 - micro_f1: 0.9068 - val_loss: 0.3427 - val_accuracy: 0.8722 - val_micro_f1: 0.8685\n\nEpoch 00127: val_micro_f1 did not improve from 0.90841\nEpoch 128/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2435 - accuracy: 0.9125 - micro_f1: 0.9125 - val_loss: 0.3171 - val_accuracy: 0.8844 - val_micro_f1: 0.8804\n\nEpoch 00128: val_micro_f1 did not improve from 0.90841\nEpoch 129/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2566 - accuracy: 0.9140 - micro_f1: 0.9140 - val_loss: 0.2862 - val_accuracy: 0.9000 - val_micro_f1: 0.9030\n\nEpoch 00129: val_micro_f1 did not improve from 0.90841\nEpoch 130/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2218 - accuracy: 0.9292 - micro_f1: 0.9292 - val_loss: 0.3253 - val_accuracy: 0.8811 - val_micro_f1: 0.8847\n\nEpoch 00130: val_micro_f1 did not improve from 0.90841\nEpoch 131/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2485 - accuracy: 0.9230 - micro_f1: 0.9230 - val_loss: 0.3007 - val_accuracy: 0.8856 - val_micro_f1: 0.8815\n\nEpoch 00131: val_micro_f1 did not improve from 0.90841\nEpoch 132/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2124 - accuracy: 0.9309 - micro_f1: 0.9309 - val_loss: 0.2990 - val_accuracy: 0.8911 - val_micro_f1: 0.8869\n\nEpoch 00132: val_micro_f1 did not improve from 0.90841\nEpoch 133/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2314 - accuracy: 0.9242 - micro_f1: 0.9242 - val_loss: 0.3172 - val_accuracy: 0.8867 - val_micro_f1: 0.8825\n\nEpoch 00133: val_micro_f1 did not improve from 0.90841\nEpoch 134/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2164 - accuracy: 0.9254 - micro_f1: 0.9255 - val_loss: 0.2636 - val_accuracy: 0.9100 - val_micro_f1: 0.9052\n\nEpoch 00134: val_micro_f1 did not improve from 0.90841\nEpoch 135/400\n66/66 [==============================] - 1s 20ms/step - loss: 0.2107 - accuracy: 0.9248 - micro_f1: 0.9248 - val_loss: 0.2819 - val_accuracy: 0.9067 - val_micro_f1: 0.9095\n\nEpoch 00135: val_micro_f1 improved from 0.90841 to 0.90948, saving model to model_save/weights-135-0.9241-0.9095.hdf5\nEpoch 136/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.2292 - accuracy: 0.9194 - micro_f1: 0.9194 - val_loss: 0.2937 - val_accuracy: 0.8922 - val_micro_f1: 0.8955\n\nEpoch 00136: val_micro_f1 did not improve from 0.90948\nEpoch 137/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.2146 - accuracy: 0.9307 - micro_f1: 0.9307 - val_loss: 0.3054 - val_accuracy: 0.9000 - val_micro_f1: 0.9030\n\nEpoch 00137: val_micro_f1 did not improve from 0.90948\nEpoch 138/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1930 - accuracy: 0.9381 - micro_f1: 0.9381 - val_loss: 0.3451 - val_accuracy: 0.8822 - val_micro_f1: 0.8858\n\nEpoch 00138: val_micro_f1 did not improve from 0.90948\nEpoch 139/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2289 - accuracy: 0.9208 - micro_f1: 0.9208 - val_loss: 0.3102 - val_accuracy: 0.8922 - val_micro_f1: 0.8879\n\nEpoch 00139: val_micro_f1 did not improve from 0.90948\nEpoch 140/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1948 - accuracy: 0.9297 - micro_f1: 0.9297 - val_loss: 0.2822 - val_accuracy: 0.9022 - val_micro_f1: 0.8976\n\nEpoch 00140: val_micro_f1 did not improve from 0.90948\nEpoch 141/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1775 - accuracy: 0.9472 - micro_f1: 0.9472 - val_loss: 0.3095 - val_accuracy: 0.8911 - val_micro_f1: 0.8793\n\nEpoch 00141: val_micro_f1 did not improve from 0.90948\nEpoch 142/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2109 - accuracy: 0.9320 - micro_f1: 0.9320 - val_loss: 0.2853 - val_accuracy: 0.9089 - val_micro_f1: 0.9116\n\nEpoch 00142: val_micro_f1 improved from 0.90948 to 0.91164, saving model to model_save/weights-142-0.9386-0.9116.hdf5\nEpoch 143/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2022 - accuracy: 0.9305 - micro_f1: 0.9305 - val_loss: 0.2840 - val_accuracy: 0.9011 - val_micro_f1: 0.8966\n\nEpoch 00143: val_micro_f1 did not improve from 0.91164\nEpoch 144/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2092 - accuracy: 0.9265 - micro_f1: 0.9265 - val_loss: 0.3121 - val_accuracy: 0.8878 - val_micro_f1: 0.8836\n\nEpoch 00144: val_micro_f1 did not improve from 0.91164\nEpoch 145/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1949 - accuracy: 0.9445 - micro_f1: 0.9445 - val_loss: 0.3163 - val_accuracy: 0.8867 - val_micro_f1: 0.8825\n\nEpoch 00145: val_micro_f1 did not improve from 0.91164\nEpoch 146/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.2033 - accuracy: 0.9306 - micro_f1: 0.9306 - val_loss: 0.2695 - val_accuracy: 0.9122 - val_micro_f1: 0.9149\n\nEpoch 00146: val_micro_f1 improved from 0.91164 to 0.91487, saving model to model_save/weights-146-0.9301-0.9149.hdf5\nEpoch 147/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.1999 - accuracy: 0.9373 - micro_f1: 0.9373 - val_loss: 0.2852 - val_accuracy: 0.9067 - val_micro_f1: 0.9095\n\nEpoch 00147: val_micro_f1 did not improve from 0.91487\nEpoch 148/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1767 - accuracy: 0.9445 - micro_f1: 0.9445 - val_loss: 0.3048 - val_accuracy: 0.8944 - val_micro_f1: 0.8976\n\nEpoch 00148: val_micro_f1 did not improve from 0.91487\nEpoch 149/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2012 - accuracy: 0.9309 - micro_f1: 0.9309 - val_loss: 0.2740 - val_accuracy: 0.9056 - val_micro_f1: 0.9084\n\nEpoch 00149: val_micro_f1 did not improve from 0.91487\nEpoch 150/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1977 - accuracy: 0.9334 - micro_f1: 0.9334 - val_loss: 0.2680 - val_accuracy: 0.9044 - val_micro_f1: 0.9073\n\nEpoch 00150: val_micro_f1 did not improve from 0.91487\nEpoch 151/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2015 - accuracy: 0.9345 - micro_f1: 0.9345 - val_loss: 0.3232 - val_accuracy: 0.8911 - val_micro_f1: 0.8944\n\nEpoch 00151: val_micro_f1 did not improve from 0.91487\nEpoch 152/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2341 - accuracy: 0.9201 - micro_f1: 0.9201 - val_loss: 0.2781 - val_accuracy: 0.9011 - val_micro_f1: 0.8966\n\nEpoch 00152: val_micro_f1 did not improve from 0.91487\nEpoch 153/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2005 - accuracy: 0.9289 - micro_f1: 0.9289 - val_loss: 0.2543 - val_accuracy: 0.9144 - val_micro_f1: 0.9170\n\nEpoch 00153: val_micro_f1 improved from 0.91487 to 0.91703, saving model to model_save/weights-153-0.9315-0.9170.hdf5\nEpoch 154/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1828 - accuracy: 0.9381 - micro_f1: 0.9381 - val_loss: 0.3474 - val_accuracy: 0.8878 - val_micro_f1: 0.8912\n\nEpoch 00154: val_micro_f1 did not improve from 0.91703\nEpoch 155/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2400 - accuracy: 0.9204 - micro_f1: 0.9204 - val_loss: 0.3049 - val_accuracy: 0.8911 - val_micro_f1: 0.8869\n\nEpoch 00155: val_micro_f1 did not improve from 0.91703\nEpoch 156/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1842 - accuracy: 0.9462 - micro_f1: 0.9462 - val_loss: 0.4116 - val_accuracy: 0.8611 - val_micro_f1: 0.8653\n\nEpoch 00156: val_micro_f1 did not improve from 0.91703\nEpoch 157/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.2195 - accuracy: 0.9266 - micro_f1: 0.9266 - val_loss: 0.3279 - val_accuracy: 0.8989 - val_micro_f1: 0.9019\n\nEpoch 00157: val_micro_f1 did not improve from 0.91703\nEpoch 158/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2022 - accuracy: 0.9376 - micro_f1: 0.9376 - val_loss: 0.2867 - val_accuracy: 0.8978 - val_micro_f1: 0.9009\n\nEpoch 00158: val_micro_f1 did not improve from 0.91703\nEpoch 159/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1757 - accuracy: 0.9461 - micro_f1: 0.9461 - val_loss: 0.3452 - val_accuracy: 0.8744 - val_micro_f1: 0.8782\n\nEpoch 00159: val_micro_f1 did not improve from 0.91703\nEpoch 160/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2108 - accuracy: 0.9268 - micro_f1: 0.9268 - val_loss: 0.3517 - val_accuracy: 0.8622 - val_micro_f1: 0.8664\n\nEpoch 00160: val_micro_f1 did not improve from 0.91703\nEpoch 161/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2241 - accuracy: 0.9313 - micro_f1: 0.9313 - val_loss: 0.3048 - val_accuracy: 0.8889 - val_micro_f1: 0.8922\n\nEpoch 00161: val_micro_f1 did not improve from 0.91703\nEpoch 162/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2029 - accuracy: 0.9360 - micro_f1: 0.9360 - val_loss: 0.2950 - val_accuracy: 0.8978 - val_micro_f1: 0.9009\n\nEpoch 00162: val_micro_f1 did not improve from 0.91703\nEpoch 163/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1847 - accuracy: 0.9342 - micro_f1: 0.9342 - val_loss: 0.2558 - val_accuracy: 0.9078 - val_micro_f1: 0.9106\n\nEpoch 00163: val_micro_f1 did not improve from 0.91703\nEpoch 164/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1859 - accuracy: 0.9341 - micro_f1: 0.9341 - val_loss: 0.2784 - val_accuracy: 0.9000 - val_micro_f1: 0.9030\n\nEpoch 00164: val_micro_f1 did not improve from 0.91703\nEpoch 165/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2061 - accuracy: 0.9280 - micro_f1: 0.9280 - val_loss: 0.2808 - val_accuracy: 0.9033 - val_micro_f1: 0.9062\n\nEpoch 00165: val_micro_f1 did not improve from 0.91703\nEpoch 166/400\n66/66 [==============================] - 1s 19ms/step - loss: 0.1854 - accuracy: 0.9366 - micro_f1: 0.9367 - val_loss: 0.2836 - val_accuracy: 0.8978 - val_micro_f1: 0.8933\n\nEpoch 00166: val_micro_f1 did not improve from 0.91703\nEpoch 167/400\n66/66 [==============================] - 1s 20ms/step - loss: 0.1773 - accuracy: 0.9372 - micro_f1: 0.9372 - val_loss: 0.2326 - val_accuracy: 0.9222 - val_micro_f1: 0.9246\n\nEpoch 00167: val_micro_f1 improved from 0.91703 to 0.92457, saving model to model_save/weights-167-0.9431-0.9246.hdf5\nEpoch 168/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1904 - accuracy: 0.9314 - micro_f1: 0.9313 - val_loss: 0.2900 - val_accuracy: 0.9022 - val_micro_f1: 0.9052\n\nEpoch 00168: val_micro_f1 did not improve from 0.92457\nEpoch 169/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1898 - accuracy: 0.9315 - micro_f1: 0.9315 - val_loss: 0.2813 - val_accuracy: 0.9078 - val_micro_f1: 0.9106\n\nEpoch 00169: val_micro_f1 did not improve from 0.92457\nEpoch 170/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1797 - accuracy: 0.9422 - micro_f1: 0.9422 - val_loss: 0.2518 - val_accuracy: 0.9178 - val_micro_f1: 0.9203\n\nEpoch 00170: val_micro_f1 did not improve from 0.92457\nEpoch 171/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1554 - accuracy: 0.9508 - micro_f1: 0.9508 - val_loss: 0.3093 - val_accuracy: 0.8911 - val_micro_f1: 0.8944\n\nEpoch 00171: val_micro_f1 did not improve from 0.92457\nEpoch 172/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1793 - accuracy: 0.9442 - micro_f1: 0.9442 - val_loss: 0.3074 - val_accuracy: 0.8844 - val_micro_f1: 0.8804\n\nEpoch 00172: val_micro_f1 did not improve from 0.92457\nEpoch 173/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1824 - accuracy: 0.9400 - micro_f1: 0.9400 - val_loss: 0.2996 - val_accuracy: 0.8833 - val_micro_f1: 0.8869\n\nEpoch 00173: val_micro_f1 did not improve from 0.92457\nEpoch 174/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1559 - accuracy: 0.9503 - micro_f1: 0.9503 - val_loss: 0.2382 - val_accuracy: 0.9300 - val_micro_f1: 0.9321\n\nEpoch 00174: val_micro_f1 improved from 0.92457 to 0.93211, saving model to model_save/weights-174-0.9395-0.9321.hdf5\nEpoch 175/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1729 - accuracy: 0.9386 - micro_f1: 0.9386 - val_loss: 0.2640 - val_accuracy: 0.9078 - val_micro_f1: 0.9106\n\nEpoch 00175: val_micro_f1 did not improve from 0.93211\nEpoch 176/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1476 - accuracy: 0.9458 - micro_f1: 0.9458 - val_loss: 0.2562 - val_accuracy: 0.9078 - val_micro_f1: 0.9106\n\nEpoch 00176: val_micro_f1 did not improve from 0.93211\nEpoch 177/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.1664 - accuracy: 0.9485 - micro_f1: 0.9485 - val_loss: 0.2785 - val_accuracy: 0.9011 - val_micro_f1: 0.9041\n\nEpoch 00177: val_micro_f1 did not improve from 0.93211\nEpoch 178/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1747 - accuracy: 0.9457 - micro_f1: 0.9457 - val_loss: 0.2737 - val_accuracy: 0.9067 - val_micro_f1: 0.9019\n\nEpoch 00178: val_micro_f1 did not improve from 0.93211\nEpoch 179/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2128 - accuracy: 0.9203 - micro_f1: 0.9204 - val_loss: 0.2651 - val_accuracy: 0.9178 - val_micro_f1: 0.9203\n\nEpoch 00179: val_micro_f1 did not improve from 0.93211\nEpoch 180/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1462 - accuracy: 0.9556 - micro_f1: 0.9556 - val_loss: 0.2890 - val_accuracy: 0.8967 - val_micro_f1: 0.8998\n\nEpoch 00180: val_micro_f1 did not improve from 0.93211\nEpoch 181/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1718 - accuracy: 0.9443 - micro_f1: 0.9443 - val_loss: 0.2434 - val_accuracy: 0.9233 - val_micro_f1: 0.9256\n\nEpoch 00181: val_micro_f1 did not improve from 0.93211\nEpoch 182/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1793 - accuracy: 0.9314 - micro_f1: 0.9314 - val_loss: 0.2495 - val_accuracy: 0.9200 - val_micro_f1: 0.9224\n\nEpoch 00182: val_micro_f1 did not improve from 0.93211\nEpoch 183/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1612 - accuracy: 0.9462 - micro_f1: 0.9462 - val_loss: 0.2478 - val_accuracy: 0.9189 - val_micro_f1: 0.9213\n\nEpoch 00183: val_micro_f1 did not improve from 0.93211\nEpoch 184/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1501 - accuracy: 0.9531 - micro_f1: 0.9531 - val_loss: 0.3017 - val_accuracy: 0.8889 - val_micro_f1: 0.8922\n\nEpoch 00184: val_micro_f1 did not improve from 0.93211\nEpoch 185/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2002 - accuracy: 0.9293 - micro_f1: 0.9293 - val_loss: 0.2966 - val_accuracy: 0.9033 - val_micro_f1: 0.9062\n\nEpoch 00185: val_micro_f1 did not improve from 0.93211\nEpoch 186/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1611 - accuracy: 0.9451 - micro_f1: 0.9451 - val_loss: 0.2617 - val_accuracy: 0.9022 - val_micro_f1: 0.9052\n\nEpoch 00186: val_micro_f1 did not improve from 0.93211\nEpoch 187/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.1614 - accuracy: 0.9420 - micro_f1: 0.9420 - val_loss: 0.2851 - val_accuracy: 0.9089 - val_micro_f1: 0.9116\n\nEpoch 00187: val_micro_f1 did not improve from 0.93211\nEpoch 188/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1842 - accuracy: 0.9235 - micro_f1: 0.9235 - val_loss: 0.2729 - val_accuracy: 0.9033 - val_micro_f1: 0.9062\n\nEpoch 00188: val_micro_f1 did not improve from 0.93211\nEpoch 189/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1572 - accuracy: 0.9447 - micro_f1: 0.9447 - val_loss: 0.2514 - val_accuracy: 0.9100 - val_micro_f1: 0.9127\n\nEpoch 00189: val_micro_f1 did not improve from 0.93211\nEpoch 190/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1747 - accuracy: 0.9395 - micro_f1: 0.9395 - val_loss: 0.2865 - val_accuracy: 0.8956 - val_micro_f1: 0.8987\n\nEpoch 00190: val_micro_f1 did not improve from 0.93211\nEpoch 191/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1677 - accuracy: 0.9368 - micro_f1: 0.9368 - val_loss: 0.2817 - val_accuracy: 0.9033 - val_micro_f1: 0.9062\n\nEpoch 00191: val_micro_f1 did not improve from 0.93211\nEpoch 192/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1770 - accuracy: 0.9419 - micro_f1: 0.9419 - val_loss: 0.2866 - val_accuracy: 0.8944 - val_micro_f1: 0.8901\n\nEpoch 00192: val_micro_f1 did not improve from 0.93211\nEpoch 193/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.1747 - accuracy: 0.9340 - micro_f1: 0.9340 - val_loss: 0.2687 - val_accuracy: 0.8956 - val_micro_f1: 0.8987\n\nEpoch 00193: val_micro_f1 did not improve from 0.93211\nEpoch 194/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1554 - accuracy: 0.9556 - micro_f1: 0.9556 - val_loss: 0.2430 - val_accuracy: 0.9144 - val_micro_f1: 0.9170\n\nEpoch 00194: val_micro_f1 did not improve from 0.93211\nEpoch 195/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1695 - accuracy: 0.9487 - micro_f1: 0.9487 - val_loss: 0.2803 - val_accuracy: 0.9044 - val_micro_f1: 0.8998\n\nEpoch 00195: val_micro_f1 did not improve from 0.93211\nEpoch 196/400\n66/66 [==============================] - 1s 21ms/step - loss: 0.1876 - accuracy: 0.9396 - micro_f1: 0.9396 - val_loss: 0.2691 - val_accuracy: 0.9089 - val_micro_f1: 0.9041\n\nEpoch 00196: val_micro_f1 did not improve from 0.93211\nEpoch 197/400\n66/66 [==============================] - 1s 19ms/step - loss: 0.1687 - accuracy: 0.9426 - micro_f1: 0.9426 - val_loss: 0.2720 - val_accuracy: 0.9078 - val_micro_f1: 0.9106\n\nEpoch 00197: val_micro_f1 did not improve from 0.93211\nEpoch 198/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1665 - accuracy: 0.9410 - micro_f1: 0.9410 - val_loss: 0.2743 - val_accuracy: 0.9056 - val_micro_f1: 0.9084\n\nEpoch 00198: val_micro_f1 did not improve from 0.93211\nEpoch 199/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1691 - accuracy: 0.9448 - micro_f1: 0.9448 - val_loss: 0.2992 - val_accuracy: 0.8911 - val_micro_f1: 0.8944\n\nEpoch 00199: val_micro_f1 did not improve from 0.93211\nEpoch 200/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1710 - accuracy: 0.9463 - micro_f1: 0.9463 - val_loss: 0.2769 - val_accuracy: 0.9078 - val_micro_f1: 0.9106\n\nEpoch 00200: val_micro_f1 did not improve from 0.93211\nEpoch 201/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1783 - accuracy: 0.9388 - micro_f1: 0.9388 - val_loss: 0.2908 - val_accuracy: 0.8889 - val_micro_f1: 0.8922\n\nEpoch 00201: val_micro_f1 did not improve from 0.93211\nEpoch 202/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1796 - accuracy: 0.9344 - micro_f1: 0.9344 - val_loss: 0.2667 - val_accuracy: 0.9144 - val_micro_f1: 0.9170\n\nEpoch 00202: val_micro_f1 did not improve from 0.93211\nEpoch 203/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1605 - accuracy: 0.9509 - micro_f1: 0.9509 - val_loss: 0.2718 - val_accuracy: 0.9044 - val_micro_f1: 0.9073\n\nEpoch 00203: val_micro_f1 did not improve from 0.93211\nEpoch 204/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1541 - accuracy: 0.9467 - micro_f1: 0.9467 - val_loss: 0.2727 - val_accuracy: 0.9044 - val_micro_f1: 0.9073\n\nEpoch 00204: val_micro_f1 did not improve from 0.93211\nEpoch 205/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1561 - accuracy: 0.9465 - micro_f1: 0.9465 - val_loss: 0.2646 - val_accuracy: 0.9056 - val_micro_f1: 0.9084\n\nEpoch 00205: val_micro_f1 did not improve from 0.93211\nEpoch 206/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1615 - accuracy: 0.9447 - micro_f1: 0.9447 - val_loss: 0.2545 - val_accuracy: 0.9056 - val_micro_f1: 0.9084\n\nEpoch 00206: val_micro_f1 did not improve from 0.93211\nEpoch 207/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.1897 - accuracy: 0.9341 - micro_f1: 0.9341 - val_loss: 0.2807 - val_accuracy: 0.8978 - val_micro_f1: 0.8933\n\nEpoch 00207: val_micro_f1 did not improve from 0.93211\nEpoch 208/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1781 - accuracy: 0.9369 - micro_f1: 0.9369 - val_loss: 0.2784 - val_accuracy: 0.8989 - val_micro_f1: 0.9019\n\nEpoch 00208: val_micro_f1 did not improve from 0.93211\nEpoch 209/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1903 - accuracy: 0.9341 - micro_f1: 0.9341 - val_loss: 0.2678 - val_accuracy: 0.9000 - val_micro_f1: 0.9030\n\nEpoch 00209: val_micro_f1 did not improve from 0.93211\nEpoch 210/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1775 - accuracy: 0.9369 - micro_f1: 0.9369 - val_loss: 0.2890 - val_accuracy: 0.8989 - val_micro_f1: 0.9019\n\nEpoch 00210: val_micro_f1 did not improve from 0.93211\nEpoch 211/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1836 - accuracy: 0.9339 - micro_f1: 0.9339 - val_loss: 0.3191 - val_accuracy: 0.8833 - val_micro_f1: 0.8869\n\nEpoch 00211: val_micro_f1 did not improve from 0.93211\nEpoch 212/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1540 - accuracy: 0.9509 - micro_f1: 0.9510 - val_loss: 0.2402 - val_accuracy: 0.9133 - val_micro_f1: 0.9159\n\nEpoch 00212: val_micro_f1 did not improve from 0.93211\nEpoch 213/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1511 - accuracy: 0.9449 - micro_f1: 0.9449 - val_loss: 0.2778 - val_accuracy: 0.9133 - val_micro_f1: 0.9159\n\nEpoch 00213: val_micro_f1 did not improve from 0.93211\nEpoch 214/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1905 - accuracy: 0.9323 - micro_f1: 0.9323 - val_loss: 0.2809 - val_accuracy: 0.9100 - val_micro_f1: 0.9127\n\nEpoch 00214: val_micro_f1 did not improve from 0.93211\nEpoch 215/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1571 - accuracy: 0.9411 - micro_f1: 0.9411 - val_loss: 0.2699 - val_accuracy: 0.9078 - val_micro_f1: 0.9030\n\nEpoch 00215: val_micro_f1 did not improve from 0.93211\nEpoch 216/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1470 - accuracy: 0.9556 - micro_f1: 0.9556 - val_loss: 0.2799 - val_accuracy: 0.9022 - val_micro_f1: 0.9052\n\nEpoch 00216: val_micro_f1 did not improve from 0.93211\nEpoch 217/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.1585 - accuracy: 0.9446 - micro_f1: 0.9446 - val_loss: 0.2858 - val_accuracy: 0.8933 - val_micro_f1: 0.8966\n\nEpoch 00217: val_micro_f1 did not improve from 0.93211\nEpoch 218/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.1526 - accuracy: 0.9455 - micro_f1: 0.9455 - val_loss: 0.2646 - val_accuracy: 0.9100 - val_micro_f1: 0.9127\n\nEpoch 00218: val_micro_f1 did not improve from 0.93211\nEpoch 219/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1869 - accuracy: 0.9329 - micro_f1: 0.9329 - val_loss: 0.2937 - val_accuracy: 0.8967 - val_micro_f1: 0.8998\n\nEpoch 00219: val_micro_f1 did not improve from 0.93211\nEpoch 220/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1483 - accuracy: 0.9524 - micro_f1: 0.9524 - val_loss: 0.2833 - val_accuracy: 0.9033 - val_micro_f1: 0.9062\n\nEpoch 00220: val_micro_f1 did not improve from 0.93211\nEpoch 221/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1582 - accuracy: 0.9417 - micro_f1: 0.9417 - val_loss: 0.2675 - val_accuracy: 0.9122 - val_micro_f1: 0.9149\n\nEpoch 00221: val_micro_f1 did not improve from 0.93211\nEpoch 222/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1584 - accuracy: 0.9430 - micro_f1: 0.9430 - val_loss: 0.3043 - val_accuracy: 0.8989 - val_micro_f1: 0.9019\n\nEpoch 00222: val_micro_f1 did not improve from 0.93211\nEpoch 223/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1839 - accuracy: 0.9335 - micro_f1: 0.9335 - val_loss: 0.3095 - val_accuracy: 0.8856 - val_micro_f1: 0.8890\n\nEpoch 00223: val_micro_f1 did not improve from 0.93211\nEpoch 224/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.2068 - accuracy: 0.9277 - micro_f1: 0.9277 - val_loss: 0.2653 - val_accuracy: 0.9044 - val_micro_f1: 0.9073\n\nEpoch 00224: val_micro_f1 did not improve from 0.93211\nEpoch 225/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.1648 - accuracy: 0.9493 - micro_f1: 0.9493 - val_loss: 0.2739 - val_accuracy: 0.9122 - val_micro_f1: 0.9149\n\nEpoch 00225: val_micro_f1 did not improve from 0.93211\nEpoch 226/400\n66/66 [==============================] - 1s 19ms/step - loss: 0.1746 - accuracy: 0.9386 - micro_f1: 0.9386 - val_loss: 0.2680 - val_accuracy: 0.9044 - val_micro_f1: 0.9073\n\nEpoch 00226: val_micro_f1 did not improve from 0.93211\nEpoch 227/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.1660 - accuracy: 0.9398 - micro_f1: 0.9398 - val_loss: 0.2598 - val_accuracy: 0.9089 - val_micro_f1: 0.9116\n\nEpoch 00227: val_micro_f1 did not improve from 0.93211\nEpoch 228/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.1348 - accuracy: 0.9539 - micro_f1: 0.9539 - val_loss: 0.2241 - val_accuracy: 0.9233 - val_micro_f1: 0.9256\n\nEpoch 00228: val_micro_f1 did not improve from 0.93211\nEpoch 229/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1287 - accuracy: 0.9582 - micro_f1: 0.9582 - val_loss: 0.3039 - val_accuracy: 0.9089 - val_micro_f1: 0.9116\n\nEpoch 00229: val_micro_f1 did not improve from 0.93211\nEpoch 230/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1603 - accuracy: 0.9501 - micro_f1: 0.9501 - val_loss: 0.3139 - val_accuracy: 0.8922 - val_micro_f1: 0.8955\n\nEpoch 00230: val_micro_f1 did not improve from 0.93211\nEpoch 231/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1541 - accuracy: 0.9455 - micro_f1: 0.9455 - val_loss: 0.2787 - val_accuracy: 0.9044 - val_micro_f1: 0.9073\n\nEpoch 00231: val_micro_f1 did not improve from 0.93211\nEpoch 232/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1577 - accuracy: 0.9456 - micro_f1: 0.9456 - val_loss: 0.2339 - val_accuracy: 0.9189 - val_micro_f1: 0.9213\n\nEpoch 00232: val_micro_f1 did not improve from 0.93211\nEpoch 233/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1336 - accuracy: 0.9555 - micro_f1: 0.9555 - val_loss: 0.2729 - val_accuracy: 0.9156 - val_micro_f1: 0.9181\n\nEpoch 00233: val_micro_f1 did not improve from 0.93211\nEpoch 234/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1429 - accuracy: 0.9483 - micro_f1: 0.9483 - val_loss: 0.2483 - val_accuracy: 0.9222 - val_micro_f1: 0.9246\n\nEpoch 00234: val_micro_f1 did not improve from 0.93211\nEpoch 235/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1550 - accuracy: 0.9365 - micro_f1: 0.9365 - val_loss: 0.2512 - val_accuracy: 0.9167 - val_micro_f1: 0.9192\n\nEpoch 00235: val_micro_f1 did not improve from 0.93211\nEpoch 236/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1436 - accuracy: 0.9520 - micro_f1: 0.9520 - val_loss: 0.2493 - val_accuracy: 0.9133 - val_micro_f1: 0.9159\n\nEpoch 00236: val_micro_f1 did not improve from 0.93211\nEpoch 237/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1446 - accuracy: 0.9557 - micro_f1: 0.9557 - val_loss: 0.2657 - val_accuracy: 0.9067 - val_micro_f1: 0.9095\n\nEpoch 00237: val_micro_f1 did not improve from 0.93211\nEpoch 238/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.1527 - accuracy: 0.9405 - micro_f1: 0.9405 - val_loss: 0.2993 - val_accuracy: 0.8900 - val_micro_f1: 0.8933\n\nEpoch 00238: val_micro_f1 did not improve from 0.93211\nEpoch 239/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1596 - accuracy: 0.9404 - micro_f1: 0.9404 - val_loss: 0.2430 - val_accuracy: 0.9189 - val_micro_f1: 0.9213\n\nEpoch 00239: val_micro_f1 did not improve from 0.93211\nEpoch 240/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1394 - accuracy: 0.9560 - micro_f1: 0.9560 - val_loss: 0.3133 - val_accuracy: 0.8867 - val_micro_f1: 0.8901\n\nEpoch 00240: val_micro_f1 did not improve from 0.93211\nEpoch 241/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1632 - accuracy: 0.9424 - micro_f1: 0.9424 - val_loss: 0.2297 - val_accuracy: 0.9222 - val_micro_f1: 0.9246\n\nEpoch 00241: val_micro_f1 did not improve from 0.93211\nEpoch 242/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1456 - accuracy: 0.9518 - micro_f1: 0.9518 - val_loss: 0.2598 - val_accuracy: 0.9111 - val_micro_f1: 0.9138\n\nEpoch 00242: val_micro_f1 did not improve from 0.93211\nEpoch 243/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1518 - accuracy: 0.9531 - micro_f1: 0.9531 - val_loss: 0.3172 - val_accuracy: 0.8967 - val_micro_f1: 0.8998\n\nEpoch 00243: val_micro_f1 did not improve from 0.93211\nEpoch 244/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1715 - accuracy: 0.9408 - micro_f1: 0.9408 - val_loss: 0.2869 - val_accuracy: 0.8889 - val_micro_f1: 0.8922\n\nEpoch 00244: val_micro_f1 did not improve from 0.93211\nEpoch 245/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1649 - accuracy: 0.9468 - micro_f1: 0.9468 - val_loss: 0.2377 - val_accuracy: 0.9189 - val_micro_f1: 0.9213\n\nEpoch 00245: val_micro_f1 did not improve from 0.93211\nEpoch 246/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1186 - accuracy: 0.9638 - micro_f1: 0.9638 - val_loss: 0.2616 - val_accuracy: 0.9089 - val_micro_f1: 0.9116\n\nEpoch 00246: val_micro_f1 did not improve from 0.93211\nEpoch 247/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1395 - accuracy: 0.9554 - micro_f1: 0.9554 - val_loss: 0.3150 - val_accuracy: 0.8956 - val_micro_f1: 0.8912\n\nEpoch 00247: val_micro_f1 did not improve from 0.93211\nEpoch 248/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.1650 - accuracy: 0.9410 - micro_f1: 0.9410 - val_loss: 0.2530 - val_accuracy: 0.9156 - val_micro_f1: 0.9181\n\nEpoch 00248: val_micro_f1 did not improve from 0.93211\nEpoch 249/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1271 - accuracy: 0.9534 - micro_f1: 0.9535 - val_loss: 0.2522 - val_accuracy: 0.9133 - val_micro_f1: 0.9159\n\nEpoch 00249: val_micro_f1 did not improve from 0.93211\nEpoch 250/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1467 - accuracy: 0.9471 - micro_f1: 0.9471 - val_loss: 0.2581 - val_accuracy: 0.9144 - val_micro_f1: 0.9170\n\nEpoch 00250: val_micro_f1 did not improve from 0.93211\nEpoch 251/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1602 - accuracy: 0.9480 - micro_f1: 0.9480 - val_loss: 0.2619 - val_accuracy: 0.9144 - val_micro_f1: 0.9170\n\nEpoch 00251: val_micro_f1 did not improve from 0.93211\nEpoch 252/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1432 - accuracy: 0.9490 - micro_f1: 0.9490 - val_loss: 0.2896 - val_accuracy: 0.9089 - val_micro_f1: 0.9116\n\nEpoch 00252: val_micro_f1 did not improve from 0.93211\nEpoch 253/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.1244 - accuracy: 0.9587 - micro_f1: 0.9587 - val_loss: 0.2865 - val_accuracy: 0.9022 - val_micro_f1: 0.9052\n\nEpoch 00253: val_micro_f1 did not improve from 0.93211\nEpoch 254/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1521 - accuracy: 0.9433 - micro_f1: 0.9433 - val_loss: 0.2718 - val_accuracy: 0.9078 - val_micro_f1: 0.9106\n\nEpoch 00254: val_micro_f1 did not improve from 0.93211\nEpoch 255/400\n66/66 [==============================] - 1s 20ms/step - loss: 0.1460 - accuracy: 0.9446 - micro_f1: 0.9446 - val_loss: 0.3421 - val_accuracy: 0.8800 - val_micro_f1: 0.8836\n\nEpoch 00255: val_micro_f1 did not improve from 0.93211\nEpoch 256/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1781 - accuracy: 0.9390 - micro_f1: 0.9390 - val_loss: 0.3177 - val_accuracy: 0.8989 - val_micro_f1: 0.9019\n\nEpoch 00256: val_micro_f1 did not improve from 0.93211\nEpoch 257/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1431 - accuracy: 0.9513 - micro_f1: 0.9513 - val_loss: 0.2464 - val_accuracy: 0.9211 - val_micro_f1: 0.9235\n\nEpoch 00257: val_micro_f1 did not improve from 0.93211\nEpoch 258/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.1338 - accuracy: 0.9547 - micro_f1: 0.9547 - val_loss: 0.2453 - val_accuracy: 0.9056 - val_micro_f1: 0.9084\n\nEpoch 00258: val_micro_f1 did not improve from 0.93211\nEpoch 259/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1583 - accuracy: 0.9422 - micro_f1: 0.9421 - val_loss: 0.2651 - val_accuracy: 0.9111 - val_micro_f1: 0.9138\n\nEpoch 00259: val_micro_f1 did not improve from 0.93211\nEpoch 260/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1451 - accuracy: 0.9520 - micro_f1: 0.9520 - val_loss: 0.2704 - val_accuracy: 0.9144 - val_micro_f1: 0.9170\n\nEpoch 00260: val_micro_f1 did not improve from 0.93211\nEpoch 261/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1618 - accuracy: 0.9414 - micro_f1: 0.9414 - val_loss: 0.2571 - val_accuracy: 0.9111 - val_micro_f1: 0.9138\n\nEpoch 00261: val_micro_f1 did not improve from 0.93211\nEpoch 262/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1401 - accuracy: 0.9552 - micro_f1: 0.9552 - val_loss: 0.2752 - val_accuracy: 0.9078 - val_micro_f1: 0.9106\n\nEpoch 00262: val_micro_f1 did not improve from 0.93211\nEpoch 263/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1323 - accuracy: 0.9532 - micro_f1: 0.9532 - val_loss: 0.2841 - val_accuracy: 0.9022 - val_micro_f1: 0.9052\n\nEpoch 00263: val_micro_f1 did not improve from 0.93211\nEpoch 264/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1488 - accuracy: 0.9456 - micro_f1: 0.9456 - val_loss: 0.2854 - val_accuracy: 0.9011 - val_micro_f1: 0.8966\n\nEpoch 00264: val_micro_f1 did not improve from 0.93211\nEpoch 265/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1482 - accuracy: 0.9473 - micro_f1: 0.9473 - val_loss: 0.2814 - val_accuracy: 0.9022 - val_micro_f1: 0.9052\n\nEpoch 00265: val_micro_f1 did not improve from 0.93211\nEpoch 266/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1496 - accuracy: 0.9445 - micro_f1: 0.9445 - val_loss: 0.2974 - val_accuracy: 0.8944 - val_micro_f1: 0.8976\n\nEpoch 00266: val_micro_f1 did not improve from 0.93211\nEpoch 267/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1818 - accuracy: 0.9327 - micro_f1: 0.9327 - val_loss: 0.2839 - val_accuracy: 0.9067 - val_micro_f1: 0.9095\n\nEpoch 00267: val_micro_f1 did not improve from 0.93211\nEpoch 268/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.1640 - accuracy: 0.9408 - micro_f1: 0.9408 - val_loss: 0.2347 - val_accuracy: 0.9200 - val_micro_f1: 0.9224\n\nEpoch 00268: val_micro_f1 did not improve from 0.93211\nEpoch 269/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1550 - accuracy: 0.9426 - micro_f1: 0.9426 - val_loss: 0.2850 - val_accuracy: 0.8989 - val_micro_f1: 0.9019\n\nEpoch 00269: val_micro_f1 did not improve from 0.93211\nEpoch 270/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1518 - accuracy: 0.9489 - micro_f1: 0.9489 - val_loss: 0.2540 - val_accuracy: 0.9256 - val_micro_f1: 0.9278\n\nEpoch 00270: val_micro_f1 did not improve from 0.93211\nEpoch 271/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1413 - accuracy: 0.9532 - micro_f1: 0.9532 - val_loss: 0.2828 - val_accuracy: 0.9133 - val_micro_f1: 0.9159\n\nEpoch 00271: val_micro_f1 did not improve from 0.93211\nEpoch 272/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1360 - accuracy: 0.9528 - micro_f1: 0.9528 - val_loss: 0.2393 - val_accuracy: 0.9144 - val_micro_f1: 0.9170\n\nEpoch 00272: val_micro_f1 did not improve from 0.93211\nEpoch 273/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1114 - accuracy: 0.9624 - micro_f1: 0.9624 - val_loss: 0.2417 - val_accuracy: 0.9133 - val_micro_f1: 0.9159\n\nEpoch 00273: val_micro_f1 did not improve from 0.93211\nEpoch 274/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1151 - accuracy: 0.9633 - micro_f1: 0.9633 - val_loss: 0.2373 - val_accuracy: 0.9233 - val_micro_f1: 0.9256\n\nEpoch 00274: val_micro_f1 did not improve from 0.93211\nEpoch 275/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1069 - accuracy: 0.9654 - micro_f1: 0.9654 - val_loss: 0.2538 - val_accuracy: 0.9156 - val_micro_f1: 0.9181\n\nEpoch 00275: val_micro_f1 did not improve from 0.93211\nEpoch 276/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1077 - accuracy: 0.9672 - micro_f1: 0.9672 - val_loss: 0.2419 - val_accuracy: 0.9267 - val_micro_f1: 0.9289\n\nEpoch 00276: val_micro_f1 did not improve from 0.93211\nEpoch 277/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1336 - accuracy: 0.9603 - micro_f1: 0.9603 - val_loss: 0.3189 - val_accuracy: 0.8956 - val_micro_f1: 0.8987\n\nEpoch 00277: val_micro_f1 did not improve from 0.93211\nEpoch 278/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.1529 - accuracy: 0.9522 - micro_f1: 0.9522 - val_loss: 0.2961 - val_accuracy: 0.9011 - val_micro_f1: 0.9041\n\nEpoch 00278: val_micro_f1 did not improve from 0.93211\nEpoch 279/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1510 - accuracy: 0.9413 - micro_f1: 0.9413 - val_loss: 0.2369 - val_accuracy: 0.9200 - val_micro_f1: 0.9224\n\nEpoch 00279: val_micro_f1 did not improve from 0.93211\nEpoch 280/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1145 - accuracy: 0.9635 - micro_f1: 0.9635 - val_loss: 0.2541 - val_accuracy: 0.9156 - val_micro_f1: 0.9181\n\nEpoch 00280: val_micro_f1 did not improve from 0.93211\nEpoch 281/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1412 - accuracy: 0.9569 - micro_f1: 0.9569 - val_loss: 0.2771 - val_accuracy: 0.9033 - val_micro_f1: 0.9062\n\nEpoch 00281: val_micro_f1 did not improve from 0.93211\nEpoch 282/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1741 - accuracy: 0.9326 - micro_f1: 0.9326 - val_loss: 0.2355 - val_accuracy: 0.9178 - val_micro_f1: 0.9203\n\nEpoch 00282: val_micro_f1 did not improve from 0.93211\nEpoch 283/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1114 - accuracy: 0.9611 - micro_f1: 0.9611 - val_loss: 0.3025 - val_accuracy: 0.8933 - val_micro_f1: 0.8966\n\nEpoch 00283: val_micro_f1 did not improve from 0.93211\nEpoch 284/400\n66/66 [==============================] - 1s 19ms/step - loss: 0.1338 - accuracy: 0.9522 - micro_f1: 0.9522 - val_loss: 0.2552 - val_accuracy: 0.9122 - val_micro_f1: 0.9149\n\nEpoch 00284: val_micro_f1 did not improve from 0.93211\nEpoch 285/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.1153 - accuracy: 0.9655 - micro_f1: 0.9655 - val_loss: 0.2256 - val_accuracy: 0.9211 - val_micro_f1: 0.9235\n\nEpoch 00285: val_micro_f1 did not improve from 0.93211\nEpoch 286/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1153 - accuracy: 0.9636 - micro_f1: 0.9636 - val_loss: 0.2157 - val_accuracy: 0.9267 - val_micro_f1: 0.9289\n\nEpoch 00286: val_micro_f1 did not improve from 0.93211\nEpoch 287/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1073 - accuracy: 0.9694 - micro_f1: 0.9694 - val_loss: 0.2529 - val_accuracy: 0.9167 - val_micro_f1: 0.9192\n\nEpoch 00287: val_micro_f1 did not improve from 0.93211\nEpoch 288/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.1224 - accuracy: 0.9582 - micro_f1: 0.9582 - val_loss: 0.2630 - val_accuracy: 0.9033 - val_micro_f1: 0.8987\n\nEpoch 00288: val_micro_f1 did not improve from 0.93211\nEpoch 289/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1256 - accuracy: 0.9584 - micro_f1: 0.9584 - val_loss: 0.2270 - val_accuracy: 0.9256 - val_micro_f1: 0.9278\n\nEpoch 00289: val_micro_f1 did not improve from 0.93211\nEpoch 290/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1019 - accuracy: 0.9722 - micro_f1: 0.9722 - val_loss: 0.2460 - val_accuracy: 0.9122 - val_micro_f1: 0.9149\n\nEpoch 00290: val_micro_f1 did not improve from 0.93211\nEpoch 291/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1217 - accuracy: 0.9582 - micro_f1: 0.9582 - val_loss: 0.2620 - val_accuracy: 0.9089 - val_micro_f1: 0.9116\n\nEpoch 00291: val_micro_f1 did not improve from 0.93211\nEpoch 292/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1268 - accuracy: 0.9541 - micro_f1: 0.9541 - val_loss: 0.3023 - val_accuracy: 0.8967 - val_micro_f1: 0.8998\n\nEpoch 00292: val_micro_f1 did not improve from 0.93211\nEpoch 293/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1141 - accuracy: 0.9615 - micro_f1: 0.9614 - val_loss: 0.2465 - val_accuracy: 0.9056 - val_micro_f1: 0.9084\n\nEpoch 00293: val_micro_f1 did not improve from 0.93211\nEpoch 294/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1481 - accuracy: 0.9471 - micro_f1: 0.9471 - val_loss: 0.2372 - val_accuracy: 0.9189 - val_micro_f1: 0.9213\n\nEpoch 00294: val_micro_f1 did not improve from 0.93211\nEpoch 295/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1394 - accuracy: 0.9487 - micro_f1: 0.9487 - val_loss: 0.2301 - val_accuracy: 0.9300 - val_micro_f1: 0.9321\n\nEpoch 00295: val_micro_f1 did not improve from 0.93211\nEpoch 296/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1075 - accuracy: 0.9617 - micro_f1: 0.9617 - val_loss: 0.2528 - val_accuracy: 0.9178 - val_micro_f1: 0.9203\n\nEpoch 00296: val_micro_f1 did not improve from 0.93211\nEpoch 297/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1262 - accuracy: 0.9603 - micro_f1: 0.9603 - val_loss: 0.2688 - val_accuracy: 0.9078 - val_micro_f1: 0.9106\n\nEpoch 00297: val_micro_f1 did not improve from 0.93211\nEpoch 298/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.1107 - accuracy: 0.9603 - micro_f1: 0.9603 - val_loss: 0.2475 - val_accuracy: 0.9167 - val_micro_f1: 0.9192\n\nEpoch 00298: val_micro_f1 did not improve from 0.93211\nEpoch 299/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.1195 - accuracy: 0.9587 - micro_f1: 0.9587 - val_loss: 0.2546 - val_accuracy: 0.9100 - val_micro_f1: 0.9127\n\nEpoch 00299: val_micro_f1 did not improve from 0.93211\nEpoch 300/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1247 - accuracy: 0.9670 - micro_f1: 0.9670 - val_loss: 0.2519 - val_accuracy: 0.9200 - val_micro_f1: 0.9224\n\nEpoch 00300: val_micro_f1 did not improve from 0.93211\nEpoch 301/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0922 - accuracy: 0.9691 - micro_f1: 0.9691 - val_loss: 0.2913 - val_accuracy: 0.9000 - val_micro_f1: 0.9030\n\nEpoch 00301: val_micro_f1 did not improve from 0.93211\nEpoch 302/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1223 - accuracy: 0.9611 - micro_f1: 0.9611 - val_loss: 0.2288 - val_accuracy: 0.9267 - val_micro_f1: 0.9289\n\nEpoch 00302: val_micro_f1 did not improve from 0.93211\nEpoch 303/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1068 - accuracy: 0.9656 - micro_f1: 0.9656 - val_loss: 0.2402 - val_accuracy: 0.9222 - val_micro_f1: 0.9246\n\nEpoch 00303: val_micro_f1 did not improve from 0.93211\nEpoch 304/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1173 - accuracy: 0.9594 - micro_f1: 0.9594 - val_loss: 0.3066 - val_accuracy: 0.8922 - val_micro_f1: 0.8955\n\nEpoch 00304: val_micro_f1 did not improve from 0.93211\nEpoch 305/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1260 - accuracy: 0.9522 - micro_f1: 0.9522 - val_loss: 0.2490 - val_accuracy: 0.9144 - val_micro_f1: 0.9170\n\nEpoch 00305: val_micro_f1 did not improve from 0.93211\nEpoch 306/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1140 - accuracy: 0.9677 - micro_f1: 0.9677 - val_loss: 0.2800 - val_accuracy: 0.9044 - val_micro_f1: 0.9073\n\nEpoch 00306: val_micro_f1 did not improve from 0.93211\nEpoch 307/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1068 - accuracy: 0.9630 - micro_f1: 0.9630 - val_loss: 0.2469 - val_accuracy: 0.9200 - val_micro_f1: 0.9224\n\nEpoch 00307: val_micro_f1 did not improve from 0.93211\nEpoch 308/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1554 - accuracy: 0.9463 - micro_f1: 0.9463 - val_loss: 0.2401 - val_accuracy: 0.9200 - val_micro_f1: 0.9224\n\nEpoch 00308: val_micro_f1 did not improve from 0.93211\nEpoch 309/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.1070 - accuracy: 0.9669 - micro_f1: 0.9669 - val_loss: 0.2518 - val_accuracy: 0.9111 - val_micro_f1: 0.9138\n\nEpoch 00309: val_micro_f1 did not improve from 0.93211\nEpoch 310/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1181 - accuracy: 0.9598 - micro_f1: 0.9598 - val_loss: 0.2747 - val_accuracy: 0.9033 - val_micro_f1: 0.9062\n\nEpoch 00310: val_micro_f1 did not improve from 0.93211\nEpoch 311/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1052 - accuracy: 0.9682 - micro_f1: 0.9682 - val_loss: 0.2552 - val_accuracy: 0.9167 - val_micro_f1: 0.9192\n\nEpoch 00311: val_micro_f1 did not improve from 0.93211\nEpoch 312/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1133 - accuracy: 0.9610 - micro_f1: 0.9610 - val_loss: 0.2517 - val_accuracy: 0.9189 - val_micro_f1: 0.9213\n\nEpoch 00312: val_micro_f1 did not improve from 0.93211\nEpoch 313/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1159 - accuracy: 0.9632 - micro_f1: 0.9632 - val_loss: 0.2337 - val_accuracy: 0.9200 - val_micro_f1: 0.9224\n\nEpoch 00313: val_micro_f1 did not improve from 0.93211\nEpoch 314/400\n66/66 [==============================] - 1s 20ms/step - loss: 0.1093 - accuracy: 0.9579 - micro_f1: 0.9579 - val_loss: 0.2754 - val_accuracy: 0.9033 - val_micro_f1: 0.9062\n\nEpoch 00314: val_micro_f1 did not improve from 0.93211\nEpoch 315/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1258 - accuracy: 0.9593 - micro_f1: 0.9593 - val_loss: 0.3130 - val_accuracy: 0.8900 - val_micro_f1: 0.8933\n\nEpoch 00315: val_micro_f1 did not improve from 0.93211\nEpoch 316/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1416 - accuracy: 0.9506 - micro_f1: 0.9506 - val_loss: 0.3049 - val_accuracy: 0.8900 - val_micro_f1: 0.8933\n\nEpoch 00316: val_micro_f1 did not improve from 0.93211\nEpoch 317/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1164 - accuracy: 0.9551 - micro_f1: 0.9550 - val_loss: 0.2441 - val_accuracy: 0.9189 - val_micro_f1: 0.9213\n\nEpoch 00317: val_micro_f1 did not improve from 0.93211\nEpoch 318/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1220 - accuracy: 0.9597 - micro_f1: 0.9597 - val_loss: 0.2592 - val_accuracy: 0.9122 - val_micro_f1: 0.9149\n\nEpoch 00318: val_micro_f1 did not improve from 0.93211\nEpoch 319/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.1358 - accuracy: 0.9559 - micro_f1: 0.9559 - val_loss: 0.2769 - val_accuracy: 0.9089 - val_micro_f1: 0.9116\n\nEpoch 00319: val_micro_f1 did not improve from 0.93211\nEpoch 320/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1315 - accuracy: 0.9488 - micro_f1: 0.9489 - val_loss: 0.2837 - val_accuracy: 0.9111 - val_micro_f1: 0.9138\n\nEpoch 00320: val_micro_f1 did not improve from 0.93211\nEpoch 321/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1585 - accuracy: 0.9354 - micro_f1: 0.9354 - val_loss: 0.2482 - val_accuracy: 0.9156 - val_micro_f1: 0.9181\n\nEpoch 00321: val_micro_f1 did not improve from 0.93211\nEpoch 322/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1265 - accuracy: 0.9569 - micro_f1: 0.9569 - val_loss: 0.2540 - val_accuracy: 0.9156 - val_micro_f1: 0.9181\n\nEpoch 00322: val_micro_f1 did not improve from 0.93211\nEpoch 323/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1485 - accuracy: 0.9509 - micro_f1: 0.9509 - val_loss: 0.2501 - val_accuracy: 0.9189 - val_micro_f1: 0.9213\n\nEpoch 00323: val_micro_f1 did not improve from 0.93211\nEpoch 324/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1474 - accuracy: 0.9536 - micro_f1: 0.9536 - val_loss: 0.3375 - val_accuracy: 0.8844 - val_micro_f1: 0.8879\n\nEpoch 00324: val_micro_f1 did not improve from 0.93211\nEpoch 325/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1806 - accuracy: 0.9364 - micro_f1: 0.9364 - val_loss: 0.3067 - val_accuracy: 0.8978 - val_micro_f1: 0.9009\n\nEpoch 00325: val_micro_f1 did not improve from 0.93211\nEpoch 326/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1201 - accuracy: 0.9600 - micro_f1: 0.9600 - val_loss: 0.2589 - val_accuracy: 0.9211 - val_micro_f1: 0.9235\n\nEpoch 00326: val_micro_f1 did not improve from 0.93211\nEpoch 327/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1110 - accuracy: 0.9632 - micro_f1: 0.9632 - val_loss: 0.2230 - val_accuracy: 0.9189 - val_micro_f1: 0.9138\n\nEpoch 00327: val_micro_f1 did not improve from 0.93211\nEpoch 328/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1375 - accuracy: 0.9595 - micro_f1: 0.9595 - val_loss: 0.2988 - val_accuracy: 0.8956 - val_micro_f1: 0.8987\n\nEpoch 00328: val_micro_f1 did not improve from 0.93211\nEpoch 329/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.1325 - accuracy: 0.9496 - micro_f1: 0.9496 - val_loss: 0.2770 - val_accuracy: 0.9044 - val_micro_f1: 0.9073\n\nEpoch 00329: val_micro_f1 did not improve from 0.93211\nEpoch 330/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1170 - accuracy: 0.9663 - micro_f1: 0.9663 - val_loss: 0.2776 - val_accuracy: 0.9167 - val_micro_f1: 0.9192\n\nEpoch 00330: val_micro_f1 did not improve from 0.93211\nEpoch 331/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1214 - accuracy: 0.9586 - micro_f1: 0.9586 - val_loss: 0.2995 - val_accuracy: 0.8989 - val_micro_f1: 0.9019\n\nEpoch 00331: val_micro_f1 did not improve from 0.93211\nEpoch 332/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1277 - accuracy: 0.9520 - micro_f1: 0.9520 - val_loss: 0.2135 - val_accuracy: 0.9278 - val_micro_f1: 0.9300\n\nEpoch 00332: val_micro_f1 did not improve from 0.93211\nEpoch 333/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1167 - accuracy: 0.9592 - micro_f1: 0.9592 - val_loss: 0.2759 - val_accuracy: 0.9044 - val_micro_f1: 0.8998\n\nEpoch 00333: val_micro_f1 did not improve from 0.93211\nEpoch 334/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1480 - accuracy: 0.9538 - micro_f1: 0.9538 - val_loss: 0.2572 - val_accuracy: 0.9078 - val_micro_f1: 0.9106\n\nEpoch 00334: val_micro_f1 did not improve from 0.93211\nEpoch 335/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1402 - accuracy: 0.9528 - micro_f1: 0.9528 - val_loss: 0.2570 - val_accuracy: 0.9100 - val_micro_f1: 0.9127\n\nEpoch 00335: val_micro_f1 did not improve from 0.93211\nEpoch 336/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1063 - accuracy: 0.9652 - micro_f1: 0.9652 - val_loss: 0.2269 - val_accuracy: 0.9289 - val_micro_f1: 0.9310\n\nEpoch 00336: val_micro_f1 did not improve from 0.93211\nEpoch 337/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1008 - accuracy: 0.9672 - micro_f1: 0.9672 - val_loss: 0.2690 - val_accuracy: 0.9078 - val_micro_f1: 0.9106\n\nEpoch 00337: val_micro_f1 did not improve from 0.93211\nEpoch 338/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1194 - accuracy: 0.9616 - micro_f1: 0.9616 - val_loss: 0.2412 - val_accuracy: 0.9178 - val_micro_f1: 0.9203\n\nEpoch 00338: val_micro_f1 did not improve from 0.93211\nEpoch 339/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.1205 - accuracy: 0.9575 - micro_f1: 0.9575 - val_loss: 0.2614 - val_accuracy: 0.9022 - val_micro_f1: 0.9052\n\nEpoch 00339: val_micro_f1 did not improve from 0.93211\nEpoch 340/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1342 - accuracy: 0.9492 - micro_f1: 0.9492 - val_loss: 0.2513 - val_accuracy: 0.9200 - val_micro_f1: 0.9224\n\nEpoch 00340: val_micro_f1 did not improve from 0.93211\nEpoch 341/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1147 - accuracy: 0.9649 - micro_f1: 0.9649 - val_loss: 0.2361 - val_accuracy: 0.9156 - val_micro_f1: 0.9181\n\nEpoch 00341: val_micro_f1 did not improve from 0.93211\nEpoch 342/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0975 - accuracy: 0.9702 - micro_f1: 0.9702 - val_loss: 0.2137 - val_accuracy: 0.9267 - val_micro_f1: 0.9289\n\nEpoch 00342: val_micro_f1 did not improve from 0.93211\nEpoch 343/400\n66/66 [==============================] - 1s 19ms/step - loss: 0.1106 - accuracy: 0.9660 - micro_f1: 0.9660 - val_loss: 0.2425 - val_accuracy: 0.9167 - val_micro_f1: 0.9192\n\nEpoch 00343: val_micro_f1 did not improve from 0.93211\nEpoch 344/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.1085 - accuracy: 0.9640 - micro_f1: 0.9640 - val_loss: 0.2350 - val_accuracy: 0.9189 - val_micro_f1: 0.9213\n\nEpoch 00344: val_micro_f1 did not improve from 0.93211\nEpoch 345/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1097 - accuracy: 0.9627 - micro_f1: 0.9627 - val_loss: 0.2475 - val_accuracy: 0.9178 - val_micro_f1: 0.9203\n\nEpoch 00345: val_micro_f1 did not improve from 0.93211\nEpoch 346/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1208 - accuracy: 0.9638 - micro_f1: 0.9638 - val_loss: 0.2209 - val_accuracy: 0.9200 - val_micro_f1: 0.9224\n\nEpoch 00346: val_micro_f1 did not improve from 0.93211\nEpoch 347/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1115 - accuracy: 0.9604 - micro_f1: 0.9604 - val_loss: 0.2479 - val_accuracy: 0.9211 - val_micro_f1: 0.9235\n\nEpoch 00347: val_micro_f1 did not improve from 0.93211\nEpoch 348/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1361 - accuracy: 0.9561 - micro_f1: 0.9561 - val_loss: 0.2941 - val_accuracy: 0.8956 - val_micro_f1: 0.8912\n\nEpoch 00348: val_micro_f1 did not improve from 0.93211\nEpoch 349/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.1115 - accuracy: 0.9646 - micro_f1: 0.9646 - val_loss: 0.2187 - val_accuracy: 0.9300 - val_micro_f1: 0.9321\n\nEpoch 00349: val_micro_f1 did not improve from 0.93211\nEpoch 350/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1087 - accuracy: 0.9677 - micro_f1: 0.9676 - val_loss: 0.2610 - val_accuracy: 0.9156 - val_micro_f1: 0.9181\n\nEpoch 00350: val_micro_f1 did not improve from 0.93211\nEpoch 351/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0907 - accuracy: 0.9734 - micro_f1: 0.9734 - val_loss: 0.2489 - val_accuracy: 0.9133 - val_micro_f1: 0.9159\n\nEpoch 00351: val_micro_f1 did not improve from 0.93211\nEpoch 352/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1166 - accuracy: 0.9604 - micro_f1: 0.9604 - val_loss: 0.2821 - val_accuracy: 0.9133 - val_micro_f1: 0.9159\n\nEpoch 00352: val_micro_f1 did not improve from 0.93211\nEpoch 353/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1021 - accuracy: 0.9649 - micro_f1: 0.9649 - val_loss: 0.2502 - val_accuracy: 0.9211 - val_micro_f1: 0.9235\n\nEpoch 00353: val_micro_f1 did not improve from 0.93211\nEpoch 354/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1118 - accuracy: 0.9587 - micro_f1: 0.9587 - val_loss: 0.2596 - val_accuracy: 0.9000 - val_micro_f1: 0.9030\n\nEpoch 00354: val_micro_f1 did not improve from 0.93211\nEpoch 355/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1306 - accuracy: 0.9601 - micro_f1: 0.9601 - val_loss: 0.3007 - val_accuracy: 0.9044 - val_micro_f1: 0.9073\n\nEpoch 00355: val_micro_f1 did not improve from 0.93211\nEpoch 356/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1034 - accuracy: 0.9681 - micro_f1: 0.9681 - val_loss: 0.2182 - val_accuracy: 0.9300 - val_micro_f1: 0.9321\n\nEpoch 00356: val_micro_f1 did not improve from 0.93211\nEpoch 357/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0987 - accuracy: 0.9670 - micro_f1: 0.9670 - val_loss: 0.2312 - val_accuracy: 0.9244 - val_micro_f1: 0.9267\n\nEpoch 00357: val_micro_f1 did not improve from 0.93211\nEpoch 358/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0972 - accuracy: 0.9661 - micro_f1: 0.9661 - val_loss: 0.2320 - val_accuracy: 0.9244 - val_micro_f1: 0.9267\n\nEpoch 00358: val_micro_f1 did not improve from 0.93211\nEpoch 359/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.0953 - accuracy: 0.9685 - micro_f1: 0.9685 - val_loss: 0.2284 - val_accuracy: 0.9200 - val_micro_f1: 0.9224\n\nEpoch 00359: val_micro_f1 did not improve from 0.93211\nEpoch 360/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0936 - accuracy: 0.9643 - micro_f1: 0.9643 - val_loss: 0.2760 - val_accuracy: 0.9100 - val_micro_f1: 0.9127\n\nEpoch 00360: val_micro_f1 did not improve from 0.93211\nEpoch 361/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1273 - accuracy: 0.9585 - micro_f1: 0.9585 - val_loss: 0.2901 - val_accuracy: 0.8978 - val_micro_f1: 0.9009\n\nEpoch 00361: val_micro_f1 did not improve from 0.93211\nEpoch 362/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1224 - accuracy: 0.9596 - micro_f1: 0.9597 - val_loss: 0.2328 - val_accuracy: 0.9200 - val_micro_f1: 0.9224\n\nEpoch 00362: val_micro_f1 did not improve from 0.93211\nEpoch 363/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1299 - accuracy: 0.9548 - micro_f1: 0.9548 - val_loss: 0.3350 - val_accuracy: 0.8878 - val_micro_f1: 0.8912\n\nEpoch 00363: val_micro_f1 did not improve from 0.93211\nEpoch 364/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1188 - accuracy: 0.9578 - micro_f1: 0.9578 - val_loss: 0.3082 - val_accuracy: 0.9056 - val_micro_f1: 0.9084\n\nEpoch 00364: val_micro_f1 did not improve from 0.93211\nEpoch 365/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0979 - accuracy: 0.9662 - micro_f1: 0.9662 - val_loss: 0.2256 - val_accuracy: 0.9344 - val_micro_f1: 0.9364\n\nEpoch 00365: val_micro_f1 improved from 0.93211 to 0.93642, saving model to model_save/weights-365-0.9665-0.9364.hdf5\nEpoch 366/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1134 - accuracy: 0.9623 - micro_f1: 0.9624 - val_loss: 0.2439 - val_accuracy: 0.9189 - val_micro_f1: 0.9213\n\nEpoch 00366: val_micro_f1 did not improve from 0.93642\nEpoch 367/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1096 - accuracy: 0.9628 - micro_f1: 0.9628 - val_loss: 0.2172 - val_accuracy: 0.9300 - val_micro_f1: 0.9321\n\nEpoch 00367: val_micro_f1 did not improve from 0.93642\nEpoch 368/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0965 - accuracy: 0.9686 - micro_f1: 0.9686 - val_loss: 0.2687 - val_accuracy: 0.9133 - val_micro_f1: 0.9159\n\nEpoch 00368: val_micro_f1 did not improve from 0.93642\nEpoch 369/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.1506 - accuracy: 0.9468 - micro_f1: 0.9468 - val_loss: 0.2552 - val_accuracy: 0.9133 - val_micro_f1: 0.9159\n\nEpoch 00369: val_micro_f1 did not improve from 0.93642\nEpoch 370/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.1046 - accuracy: 0.9586 - micro_f1: 0.9585 - val_loss: 0.2589 - val_accuracy: 0.9133 - val_micro_f1: 0.9159\n\nEpoch 00370: val_micro_f1 did not improve from 0.93642\nEpoch 371/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0968 - accuracy: 0.9687 - micro_f1: 0.9687 - val_loss: 0.2724 - val_accuracy: 0.9167 - val_micro_f1: 0.9116\n\nEpoch 00371: val_micro_f1 did not improve from 0.93642\nEpoch 372/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.0973 - accuracy: 0.9582 - micro_f1: 0.9582 - val_loss: 0.2464 - val_accuracy: 0.9222 - val_micro_f1: 0.9246\n\nEpoch 00372: val_micro_f1 did not improve from 0.93642\nEpoch 373/400\n66/66 [==============================] - 1s 19ms/step - loss: 0.1005 - accuracy: 0.9597 - micro_f1: 0.9596 - val_loss: 0.2431 - val_accuracy: 0.9156 - val_micro_f1: 0.9181\n\nEpoch 00373: val_micro_f1 did not improve from 0.93642\nEpoch 374/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0771 - accuracy: 0.9802 - micro_f1: 0.9802 - val_loss: 0.2449 - val_accuracy: 0.9178 - val_micro_f1: 0.9203\n\nEpoch 00374: val_micro_f1 did not improve from 0.93642\nEpoch 375/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0937 - accuracy: 0.9754 - micro_f1: 0.9754 - val_loss: 0.2525 - val_accuracy: 0.9178 - val_micro_f1: 0.9203\n\nEpoch 00375: val_micro_f1 did not improve from 0.93642\nEpoch 376/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0919 - accuracy: 0.9726 - micro_f1: 0.9726 - val_loss: 0.2452 - val_accuracy: 0.9256 - val_micro_f1: 0.9278\n\nEpoch 00376: val_micro_f1 did not improve from 0.93642\nEpoch 377/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0925 - accuracy: 0.9672 - micro_f1: 0.9672 - val_loss: 0.2535 - val_accuracy: 0.9256 - val_micro_f1: 0.9278\n\nEpoch 00377: val_micro_f1 did not improve from 0.93642\nEpoch 378/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1138 - accuracy: 0.9610 - micro_f1: 0.9610 - val_loss: 0.2312 - val_accuracy: 0.9200 - val_micro_f1: 0.9224\n\nEpoch 00378: val_micro_f1 did not improve from 0.93642\nEpoch 379/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.0836 - accuracy: 0.9732 - micro_f1: 0.9733 - val_loss: 0.2461 - val_accuracy: 0.9178 - val_micro_f1: 0.9203\n\nEpoch 00379: val_micro_f1 did not improve from 0.93642\nEpoch 380/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0908 - accuracy: 0.9726 - micro_f1: 0.9726 - val_loss: 0.2440 - val_accuracy: 0.9144 - val_micro_f1: 0.9170\n\nEpoch 00380: val_micro_f1 did not improve from 0.93642\nEpoch 381/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1336 - accuracy: 0.9523 - micro_f1: 0.9523 - val_loss: 0.2766 - val_accuracy: 0.9089 - val_micro_f1: 0.9116\n\nEpoch 00381: val_micro_f1 did not improve from 0.93642\nEpoch 382/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1243 - accuracy: 0.9612 - micro_f1: 0.9612 - val_loss: 0.2272 - val_accuracy: 0.9233 - val_micro_f1: 0.9256\n\nEpoch 00382: val_micro_f1 did not improve from 0.93642\nEpoch 383/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0882 - accuracy: 0.9679 - micro_f1: 0.9679 - val_loss: 0.2589 - val_accuracy: 0.9100 - val_micro_f1: 0.9127\n\nEpoch 00383: val_micro_f1 did not improve from 0.93642\nEpoch 384/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1131 - accuracy: 0.9609 - micro_f1: 0.9609 - val_loss: 0.2765 - val_accuracy: 0.9100 - val_micro_f1: 0.9127\n\nEpoch 00384: val_micro_f1 did not improve from 0.93642\nEpoch 385/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0969 - accuracy: 0.9681 - micro_f1: 0.9681 - val_loss: 0.2697 - val_accuracy: 0.9178 - val_micro_f1: 0.9203\n\nEpoch 00385: val_micro_f1 did not improve from 0.93642\nEpoch 386/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1117 - accuracy: 0.9600 - micro_f1: 0.9600 - val_loss: 0.2126 - val_accuracy: 0.9367 - val_micro_f1: 0.9386\n\nEpoch 00386: val_micro_f1 improved from 0.93642 to 0.93858, saving model to model_save/weights-386-0.9683-0.9386.hdf5\nEpoch 387/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1008 - accuracy: 0.9664 - micro_f1: 0.9664 - val_loss: 0.2093 - val_accuracy: 0.9289 - val_micro_f1: 0.9310\n\nEpoch 00387: val_micro_f1 did not improve from 0.93858\nEpoch 388/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0912 - accuracy: 0.9688 - micro_f1: 0.9688 - val_loss: 0.2358 - val_accuracy: 0.9200 - val_micro_f1: 0.9224\n\nEpoch 00388: val_micro_f1 did not improve from 0.93858\nEpoch 389/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.1083 - accuracy: 0.9624 - micro_f1: 0.9624 - val_loss: 0.2724 - val_accuracy: 0.9089 - val_micro_f1: 0.9116\n\nEpoch 00389: val_micro_f1 did not improve from 0.93858\nEpoch 390/400\n66/66 [==============================] - 1s 17ms/step - loss: 0.1200 - accuracy: 0.9549 - micro_f1: 0.9549 - val_loss: 0.2331 - val_accuracy: 0.9256 - val_micro_f1: 0.9278\n\nEpoch 00390: val_micro_f1 did not improve from 0.93858\nEpoch 391/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0909 - accuracy: 0.9631 - micro_f1: 0.9631 - val_loss: 0.2475 - val_accuracy: 0.9278 - val_micro_f1: 0.9300\n\nEpoch 00391: val_micro_f1 did not improve from 0.93858\nEpoch 392/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0797 - accuracy: 0.9752 - micro_f1: 0.9752 - val_loss: 0.2334 - val_accuracy: 0.9244 - val_micro_f1: 0.9267\n\nEpoch 00392: val_micro_f1 did not improve from 0.93858\nEpoch 393/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0884 - accuracy: 0.9743 - micro_f1: 0.9744 - val_loss: 0.2411 - val_accuracy: 0.9256 - val_micro_f1: 0.9278\n\nEpoch 00393: val_micro_f1 did not improve from 0.93858\nEpoch 394/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0759 - accuracy: 0.9789 - micro_f1: 0.9789 - val_loss: 0.2806 - val_accuracy: 0.9156 - val_micro_f1: 0.9181\n\nEpoch 00394: val_micro_f1 did not improve from 0.93858\nEpoch 395/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1214 - accuracy: 0.9547 - micro_f1: 0.9547 - val_loss: 0.2790 - val_accuracy: 0.9144 - val_micro_f1: 0.9170\n\nEpoch 00395: val_micro_f1 did not improve from 0.93858\nEpoch 396/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1045 - accuracy: 0.9626 - micro_f1: 0.9626 - val_loss: 0.3165 - val_accuracy: 0.9022 - val_micro_f1: 0.9052\n\nEpoch 00396: val_micro_f1 did not improve from 0.93858\nEpoch 397/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1154 - accuracy: 0.9589 - micro_f1: 0.9589 - val_loss: 0.2294 - val_accuracy: 0.9256 - val_micro_f1: 0.9278\n\nEpoch 00397: val_micro_f1 did not improve from 0.93858\nEpoch 398/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.0932 - accuracy: 0.9700 - micro_f1: 0.9700 - val_loss: 0.2372 - val_accuracy: 0.9267 - val_micro_f1: 0.9289\n\nEpoch 00398: val_micro_f1 did not improve from 0.93858\nEpoch 399/400\n66/66 [==============================] - 1s 16ms/step - loss: 0.1192 - accuracy: 0.9619 - micro_f1: 0.9619 - val_loss: 0.2358 - val_accuracy: 0.9178 - val_micro_f1: 0.9203\n\nEpoch 00399: val_micro_f1 did not improve from 0.93858\nEpoch 400/400\n66/66 [==============================] - 1s 18ms/step - loss: 0.1019 - accuracy: 0.9645 - micro_f1: 0.9645 - val_loss: 0.2432 - val_accuracy: 0.9211 - val_micro_f1: 0.9235\n\nEpoch 00400: val_micro_f1 did not improve from 0.93858\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f055c202150>"},"metadata":{}}]},{"cell_type":"code","source":"opt_res=os.listdir(\"model_save/\")","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:23:44.479833Z","iopub.execute_input":"2021-09-16T14:23:44.480083Z","iopub.status.idle":"2021-09-16T14:23:44.486448Z","shell.execute_reply.started":"2021-09-16T14:23:44.480051Z","shell.execute_reply":"2021-09-16T14:23:44.485734Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"result=pd.DataFrame()\nepoch=[]\nf1=[]\nval_f1=[]\nfor i in opt_res:    \n    epoch.append(i.split('-')[1])\n    f1.append(i.split('-')[2])\n    val_f1.append(i.split('-')[3][:6])\nresult['epoch']=epoch\nresult['f1']=f1\nresult['val_f1']=val_f1\nvalues=result[result.epoch==str(result.epoch.astype('int').max())]","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:23:44.488000Z","iopub.execute_input":"2021-09-16T14:23:44.488255Z","iopub.status.idle":"2021-09-16T14:23:44.500468Z","shell.execute_reply.started":"2021-09-16T14:23:44.488223Z","shell.execute_reply":"2021-09-16T14:23:44.499772Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print(\"We have found optimum result at\\nEpoch: \",values.iloc[0].epoch,\"\\nTrain F1 score: \",values.iloc[0].f1,\"\\nTest F1 score: \",values.iloc[0].val_f1)","metadata":{"execution":{"iopub.status.busy":"2021-09-16T14:23:44.502140Z","iopub.execute_input":"2021-09-16T14:23:44.502436Z","iopub.status.idle":"2021-09-16T14:23:44.511837Z","shell.execute_reply.started":"2021-09-16T14:23:44.502403Z","shell.execute_reply":"2021-09-16T14:23:44.511155Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"We have found optimum result at\nEpoch:  386 \nTrain F1 score:  0.9683 \nTest F1 score:  0.9386\n","output_type":"stream"}]}]}